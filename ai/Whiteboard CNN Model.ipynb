{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bbe166ba-8e22-4f31-b036-1dab0836f4d6",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Plan de la présentation\n",
    "\n",
    "I. Introduction sur les CNN\n",
    "\n",
    "1. Qu'est ce qu'un CNN\n",
    "2. Pourquoi avoir choisi de construire un modèle CNN\n",
    "\n",
    "II. Préparation du dataset\n",
    "\n",
    "1. Séparation du dataset (train, validation, test)\n",
    "2. Choix des classes et itération sur le dataset\n",
    "3. Prétraitement et normalisation des images\n",
    "\n",
    "III. Construction, entrainement et testing du modèle\n",
    "\n",
    "1. Construction du modèle\n",
    "2. Entrainement du modèle\n",
    "3. Testing de l'efficacité du modèle\n",
    "\n",
    "IV. Conclusion\n",
    "\n",
    "V. Quelques sources scientifiques utilisées"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc7e5c9-55cb-44ab-b791-c287a5d5cc3b",
   "metadata": {},
   "source": [
    "## I. Introduction sur les CNN\n",
    "\n",
    "### 1. Qu'est-ce qu'un CNN\n",
    "\n",
    "Les CNN sont une catégorie de réseaux de neurones artificiels profonds, principalement utilisés pour traiter des données ayant une topologie de grille, comme les images. Un CNN se compose de plusieurs couches conçues pour reconnaître des patterns de plus en plus complexes au fur et à mesure que les données progressent à travers le réseau.\n",
    "\n",
    "Les éléments clés qui constituent un CNN incluent :\n",
    "\n",
    "- **Les layers de convolution**, où des filtres / kernels sont appliqués sur l'entrée pour créer des \"feature maps\". Cela permet de détécter des spécificités de l'image, comme des bords, des courbes, des concentrations de couleurs etc...\n",
    "  \n",
    "- **Les layers de pooling**, qui sont appliqués sur les feature maps pour réduire leur taille. On utilise en général du max pooling 2x2, permettant de garder, sur une matrice de 4 pixels, seulement le pixel max (celui qui a la plus haute valeur en grayscale par exemple). Garder le pixel max permet de réduire la taille de l'image tout en conservant les informations importantes de l'image.\n",
    "  \n",
    "- **Les layers de normalisation**, qui aident à accélérer la convergence du réseau en normalisant les entrées de chaque couche. Par exemple, sur une liste de valeurs d'activation de neurone a une étape donnée, la normalisation va convertir toutes ces valeurs à des valeurs entre 0 et 1 (car la sortie est composée de n neurones, n étant le nombre de classes, dont chaque valeur est la probabilité de la prédiction, donc entre 0 et 1, somme = 1)\n",
    "  \n",
    "- **Le layer complètement connecté** (ou fully connected layer), où tous les neurones d'une couche sont connectés à chaque neurone de la couche suivante, permettant de classer les données en fonction des caractéristiques extraites par les couches précédentes.\n",
    "\n",
    "La capacité des CNN à détecter des caractéristiques d'une image par convolution et maxpooling un les rend particulièrement adaptés pour des tâches de vision par ordinateur telles que la classification d'images, la reconnaissance de formes et la détection d'objets.\n",
    "\n",
    "### 2. Pourquoi avoir choisi de faire un modèle CNN\n",
    "\n",
    "Les CNN ont été choisis pour ce projet de classification de formes dessinées à la main pour plusieurs raisons :\n",
    "\n",
    "- **Capacité à extraire des caractéristiques locales** : Les CNN sont capables d'identifier des caractéristiques locales dans des images, comme les bords et les formes simples, qui sont cruciales pour différencier des formes géométriques comme les ellipses, les rectangles et les triangles.\n",
    "  \n",
    "- **Invariance spatiale** : Les CNN peuvent reconnaître des formes indépendamment de leur position dans l'image grâce aux opérations de convolution et de pooling, ce qui est idéal pour traiter des dessins à main levée qui peuvent varier en orientation et en position.\n",
    "  \n",
    "- **Performance de pointe** : Les CNN ont démontré une performance exceptionnelle sur diverses tâches de vision par ordinateur, y compris la classification d'images, surpassant les approches classiques et d'autres architectures de réseaux de neurones dans de nombreux cas.\n",
    "  \n",
    "- **Adaptabilité et apprentissage profond** : La capacité des CNN à apprendre des représentations de données profondes et hiérarchiques leur permet de s'adapter et de généraliser à partir d'un ensemble de données d'entraînement vers de nouvelles formes inédites, ce qui est essentiel pour un système robuste de reconnaissance de formes.\n",
    "\n",
    "**Références**:\n",
    "- *Krizhevsky, A., Sutskever, I., & Hinton, G. E. (2012). ImageNet classification with deep convolutional neural networks. In Advances in neural information processing systems (pp. 1097-1105).* Cet article décrit l'architecture AlexNet, un CNN qui a largement remporté le [défi ImageNet LSVRC-2012](https://image-net.org/challenges/LSVRC/2012/results.html) face au state of the art, démontrant l'efficacité des CNN pour la classification d'images.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2d76eaa-d482-435a-9d4d-f6f5ecfe6dbc",
   "metadata": {},
   "source": [
    "## II. Préparation du dataset\n",
    "\n",
    "Commençons a préparer notre dataset. Tout d'abord, importons les librairies nécessaires :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e1ec273-209a-4019-9f40-18e872f9a0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-28 22:31:34.120655: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-04-28 22:31:35.273444: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from time import sleep\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.layers import (\n",
    "    Activation,\n",
    "    BatchNormalization,\n",
    "    Conv2D,\n",
    "    Dense,\n",
    "    Dropout,\n",
    "    Flatten,\n",
    "    Input,\n",
    "    MaxPooling2D,\n",
    ")\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.utils import to_categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1924479-bcda-403c-bc6c-df0aae63cc45",
   "metadata": {},
   "source": [
    "Initialisons maintenant les variables globales et les constantes nécessaires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b62f8cfc-71bf-4ff4-9669-b7eace9bb37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "main_dir = \"data/\"\n",
    "img_size = 70\n",
    "\n",
    "train_images = []\n",
    "train_labels = []\n",
    "validation_images = []\n",
    "validation_labels = []\n",
    "test_images = []\n",
    "test_labels = []\n",
    "class_names = {}\n",
    "class_index = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3caccaf0-ab02-48c7-b35d-df56d11dfeb0",
   "metadata": {},
   "source": [
    "Définissions maintenant les classes de sortie, les outputs que doit prédire le modèle, et une fonction utilitaire"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "49f813c7-9738-407b-affa-5a5edc7d917b",
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_classes = {\n",
    "    \"other\": 0,\n",
    "    \"ellipse\": 1,\n",
    "    \"rectangle\": 2,\n",
    "    \"triangle\": 3,\n",
    "}\n",
    "\n",
    "num_classes = len(shape_classes)\n",
    "\n",
    "def get_class_name(class_index):\n",
    "    for class_name, index in shape_classes.items():\n",
    "        if index == class_index:\n",
    "            return class_name\n",
    "    return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e21d9da2-1a90-4683-8cf3-71af293bffe2",
   "metadata": {},
   "source": [
    "### 1. Séparation du dataset (train, validation, test)\n",
    "\n",
    "Séparer un dataset en train, validation et test est une pratique standard qui sert à optimiser et évaluer la performance des modèles de manière non biasée.\n",
    "\n",
    "- La partie d'entraînement est utilisée pour ajuster les paramètres du modèle, c'est-à-dire que le modèle apprend à reconnaître des patterns ou des caractéristiques à partir de cette portion de données.\n",
    "  \n",
    "- La partie de validation, quant à elle, est utilisée pour affiner les hyperparamètres du modèle (comme le taux d'apprentissage ou le nombre de couches dans un réseau de neurones) et pour prévenir le surajustement (overfitting), qui survient lorsque le modèle apprend trop bien les données d'entraînement jusqu'à ne pas pouvoir être appliqué sur de nouvelles données.\n",
    "\n",
    "- Enfin, la partie de test sert à évaluer la performance générale du modèle sur un jeu de données jamais vu auparavant, fournissant ainsi une mesure objective de sa capacité à généraliser. Nous l'utilisons pour notamment évaluer le degré d'overfitting.\n",
    "\n",
    "*Nous séparons le dataset (train, validation, test) selon les recommandations du créateur du dataset.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "085061f9-d2da-4b5f-bff1-f09cbed3cac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_users = [\"crt\", \"il1\", \"lts\", \"mrt\", \"nae\"]\n",
    "\n",
    "test_users = [\"u01\", \"u17\", \"u18\", \"u19\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f882b2e5-0ce8-4dfb-bf2c-be3e60ae694b",
   "metadata": {},
   "source": [
    "### 2. Itération et traitement du dataset\n",
    "\n",
    "Ajoutons d'abord une fonction utilitaire qui s'occupe de pré-traiter les images (grayscale et resize) :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "08ea5e30-504f-4b2d-8c52-d8b906db1118",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process_image(image_path):\n",
    "    \"\"\"Pre-process the image, load it, grayscale it, and resize it\"\"\"\n",
    "    image = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)\n",
    "    image = cv2.resize(image, (img_size, img_size))\n",
    "    return image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3d02045-48be-4f7a-8243-00e99b984e8a",
   "metadata": {},
   "source": [
    "L'itération sur le dataset et l'importation est majoritairement fait par cette fonction qui itère sur un dossier, pre-process et charge en mémoire les images du dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1a2a93fc-bb70-49fb-8138-76fa358c0a3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_directory(directory, images, labels):\n",
    "    \"\"\"Process the directory and add images to the specified set\"\"\"\n",
    "    print(f\"Processing directory: {directory}\")\n",
    "    for shape_type in os.listdir(directory):\n",
    "        for img in os.listdir(directory + shape_type):\n",
    "            if not img.endswith(\".png\") and not img.endswith(\".jpg\"):\n",
    "                continue\n",
    "            full_path = os.path.join(directory, shape_type, img)\n",
    "            image = pre_process_image(full_path)\n",
    "            images.append(image)\n",
    "            labels.append(shape_classes[os.path.basename(shape_type)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0aecc8fb-18f1-4bbe-a264-ca699cb7fe80",
   "metadata": {},
   "source": [
    "Pour le **training** data set, nous utilisons cette fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7b29da92-0ffa-49de-9d3e-4af6ceefd802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def walk_training_data():\n",
    "    \"\"\"Walk on the data directory and process the images\"\"\"\n",
    "    print(\"Walking on the data directory...\")\n",
    "    for directory in os.listdir(main_dir):\n",
    "        if directory in validation_users or directory in test_users:\n",
    "            continue\n",
    "        process_directory(main_dir + directory + \"/images/\", train_images, train_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da4cba9d-4890-4d55-8651-b3b17f41a9e1",
   "metadata": {},
   "source": [
    "**Petite démo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8bd14e0b-0b22-4711-946d-6e221c7553de",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Walking on the data directory...\n",
      "Processing directory: data/user.vly/images/\n",
      "Processing directory: data/user.u01/images/\n",
      "Processing directory: data/user.u17/images/\n",
      "Processing directory: data/user.if8/images/\n",
      "Processing directory: data/user.frt/images/\n",
      "Processing directory: data/user.u18/images/\n",
      "Processing directory: data/user.crt/images/\n",
      "Processing directory: data/user.if1/images/\n",
      "Processing directory: data/user.lrt/images/\n",
      "Processing directory: data/user.u06/images/\n",
      "Processing directory: data/user.u07/images/\n",
      "Processing directory: data/user.lts/images/\n",
      "Processing directory: data/user.u02/images/\n",
      "Processing directory: data/user.u13/images/\n",
      "Processing directory: data/user.u03/images/\n",
      "Processing directory: data/user.nae/images/\n",
      "Processing directory: data/user.elu/images/\n",
      "Processing directory: data/user.if3/images/\n",
      "Processing directory: data/user.u05/images/\n",
      "Processing directory: data/user.mrt/images/\n",
      "Processing directory: data/user.u10/images/\n",
      "Processing directory: data/user.il1/images/\n",
      "Processing directory: data/user.u12/images/\n",
      "Processing directory: data/user.if5/images/\n",
      "Processing directory: data/user.u11/images/\n",
      "Processing directory: data/user.nld/images/\n",
      "Processing directory: data/user.u08/images/\n",
      "Processing directory: data/user.u09/images/\n",
      "Processing directory: data/user.if2/images/\n",
      "Processing directory: data/user.lt1/images/\n",
      "Processing directory: data/user.u14/images/\n",
      "Processing directory: data/user.u04/images/\n",
      "Processing directory: data/user.aly/images/\n",
      "Processing directory: data/user.u19/images/\n",
      "Processing directory: data/user.ilb/images/\n",
      "Processing directory: data/user.im1/images/\n",
      "Processing directory: data/user.drt/images/\n"
     ]
    }
   ],
   "source": [
    "walk_training_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4e300e0-d041-452d-b575-2303d9d39281",
   "metadata": {},
   "source": [
    "Pour le **validation** data set, nous utilisons cette fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "beb75c3b-7866-42d0-a800-f9ef3d75eb31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_validation_data():\n",
    "    \"\"\"Prepare data for validation\"\"\"\n",
    "    print(\"Preparing data for validation...\")\n",
    "    for directory in validation_users:\n",
    "        process_directory(\n",
    "            main_dir + \"user.\" + directory + \"/images/\",\n",
    "            validation_images,\n",
    "            validation_labels,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3f02cd3-e379-46d6-a8ce-4ac57bb01dd2",
   "metadata": {},
   "source": [
    "**Petite démo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76fe0c94-bfd5-42b1-bdbe-1cad72f2f02b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for validation...\n",
      "Processing directory: data/user.crt/images/\n",
      "Processing directory: data/user.il1/images/\n",
      "Processing directory: data/user.lts/images/\n",
      "Processing directory: data/user.mrt/images/\n",
      "Processing directory: data/user.nae/images/\n"
     ]
    }
   ],
   "source": [
    "prepare_validation_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2c50e1e-a2d6-4dc6-99dd-c214343675ff",
   "metadata": {},
   "source": [
    "Pour le **test** data set, nous utilisons cette fonction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d140372-e13d-4d1c-9f8d-42765aabbbd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_test_data():\n",
    "    \"\"\"Prepare data for testing\"\"\"\n",
    "    print(\"Preparing data for testing...\")\n",
    "    for directory in test_users:\n",
    "        process_directory(\n",
    "            main_dir + \"user.\" + directory + \"/images/\", test_images, test_labels\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a758eeb2-e788-4292-a460-79b0654af0b6",
   "metadata": {},
   "source": [
    "**Petite démo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4850c272-0381-4914-a977-b09b8b823fb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for testing...\n",
      "Processing directory: data/user.u01/images/\n",
      "Processing directory: data/user.u17/images/\n",
      "Processing directory: data/user.u18/images/\n",
      "Processing directory: data/user.u19/images/\n"
     ]
    }
   ],
   "source": [
    "prepare_test_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85cc1ee2-d6eb-4ae0-8487-091bc66b6a2c",
   "metadata": {},
   "source": [
    "## III. Prétraitement et normalisation des images\n",
    "\n",
    "Nous avons effectué une étape de prétraitement des images à l'étape précedente avec la fonction utilitaire `pre_process_image`.\n",
    "\n",
    "Nous allons maintenant normaliser notre data. A quoi cela sert ?\n",
    "\n",
    "Imaginons une image grayscale (valeur du pixel de 0 a 255), donc un input allant de 0 a 255. Notre output doit être entre 0 et 1.\n",
    "\n",
    "En gardant ces valeurs de 0 a 255, notre modèle prendra énormément de temps a converger. Nous normalisons donc chaque pixel en divisant chaque valeur par 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0d43fc40-0178-4cac-8b5a-24fa18dcfeb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_data_for_training():\n",
    "    \"\"\"Prepare the whole data for training\"\"\"\n",
    "    print(\"Preparing data for training...\")\n",
    "    global train_images, train_labels, validation_images, validation_labels, test_images, test_labels\n",
    "    train_images = np.array(train_images) / 255.0\n",
    "    train_labels = np.array(train_labels)\n",
    "\n",
    "    validation_images = np.array(validation_images) / 255.0\n",
    "    validation_labels = np.array(validation_labels)\n",
    "\n",
    "    test_images = np.array(test_images) / 255.0\n",
    "    test_labels = np.array(test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb216fb-07d7-4bf3-a77c-3c4b75d93a41",
   "metadata": {},
   "source": [
    "**Petite démo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5d4fc2c4-014c-4cf8-b50b-2e3db907f054",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing data for training...\n"
     ]
    }
   ],
   "source": [
    "prepare_data_for_training()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6ec16b-0e1f-4a2c-9647-92f68a96c075",
   "metadata": {},
   "source": [
    "## III. Construction, entrainement et testing du modèle\n",
    "\n",
    "À présent, commençons a construire notre modèle CNN, en expliquant et sourçant chaque choix.\n",
    "\n",
    "Voici comment nous avons procédé :\n",
    "\n",
    "1. Construire le CNN le plus simple possible. Il ressemblerait à cela :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "78032957-71f7-4cdc-aec7-3df77f50bc42",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ryn/.local/lib/python3.12/site-packages/keras/src/layers/convolutional/base_conv.py:99: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(\n",
      "2024-04-28 22:32:59.566463: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-28 22:32:59.821411: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-28 22:32:59.821756: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-28 22:32:59.827451: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-28 22:32:59.827750: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-28 22:32:59.828202: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-28 22:33:00.060043: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-28 22:33:00.060308: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-28 22:33:00.060321: I tensorflow/core/common_runtime/gpu/gpu_device.cc:2019] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2024-04-28 22:33:00.060629: I external/local_xla/xla/stream_executor/cuda/cuda_executor.cc:984] could not open file to read NUMA node: /sys/bus/pci/devices/0000:09:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2024-04-28 22:33:00.061224: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1928] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 6055 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 2080 SUPER, pci bus id: 0000:09:00.0, compute capability: 7.5\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">13</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">5408</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │        <span style=\"color: #00af00; text-decoration-color: #00af00\">21,636</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m13\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m5408\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │        \u001b[38;5;34m21,636\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,956</span> (85.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m21,956\u001b[0m (85.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">21,956</span> (85.77 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m21,956\u001b[0m (85.77 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from tensorflow.keras import layers, models\n",
    "\n",
    "input_shape = (28, 28, 1)\n",
    "num_classes = 4 # Ellipse, Rectangle, Triangle, Other\n",
    "\n",
    "model = models.Sequential()\n",
    "\n",
    "# Add a simple convolutional layer with 32 filters, a kernel size of 3x3, \n",
    "# activation function ReLU, and the defined input shape\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "\n",
    "# Add a max pooling layer to reduce the spatial dimensions of the output volume\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Flatten the 3D output to 1D to feed it into the dense layer\n",
    "model.add(layers.Flatten())\n",
    "\n",
    "# Add a dense layer for classification. \n",
    "# Assuming a simple binary classification, hence units=1 and activation='sigmoid'.\n",
    "model.add(layers.Dense(num_classes, activation='softmax'))\n",
    "\n",
    "# Compile the model specifying the optimizer, loss, and metrics to monitor\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Show model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6458d253-6f91-4dbb-8756-6c46a02a62fb",
   "metadata": {},
   "source": [
    "Évidemment, il ne convergera jamais vers une accuracy raisonnable, car après les convolutions et maxpooling, le Flatten() donne 5408 paramètres d'input. Les connecter a un fully connected layer de 4 neurones est tout simplement trop peu.\n",
    "\n",
    "L'étape suivante est d'ajouter un fully connected layer (Dense), rajoutant de la complexité.\n",
    "\n",
    "Puis d'observer les pratiques scientifiques et de l'industrie pour connaître les bonnes pratiques permettant une meilleur accuracy :\n",
    "\n",
    "- Ajouter plus de layer Dense\n",
    "- Ajouter plus de convolutions + maxpooling\n",
    "- Ajouter du dropout pour réduire l'overfitting\n",
    "- Placer stratégiquement le maxpooling et le dropout pour viser uniquement les feature maps profondes\n",
    "- Utiliser d'autres fonctions d'activations (par exemple mish, relu, etc)\n",
    "- Changer le nombre de feature maps (conv2d) a chaque étape\n",
    "- Normaliser les input a des étapes stratégiques (BatchNormalization)\n",
    "- Déformer intentionnellement les images d'entrainement pour réduire l'overfitting (ajouter du zoom, rotation, padding, symmétries, etc...)\n",
    "- Utiliser des Learning Rate Scheduler, qui réduisent stratégiquement la vitesse d'entrainement (du gradient descent) lorsqu'on se rapproche de la convergence\n",
    "- Réduire / Augmenter le nombre d'épochs (influence énormément la vitesse d'entrainement)\n",
    "- Changer des valeurs a une étape x du modèle et benchmark la différence sur l'accuracy\n",
    "\n",
    "Cette partie est celle qui nous a pris le plus de temps sur ce projet, surtout lorsque nous prenons en compte le temps d'entrainement. Après tout, le machine learning est avant tout une science d'expérimentation.\n",
    "\n",
    "Voici une citation de [Jason Brownlee](https://scholar.google.com/citations?user=hVaJhRYAAAAJ&hl=en), scientifique renommé dans le deep / machine learning:\n",
    "\n",
    "*\"In applied machine learning, you must become the scientist and perform systematic experiments.*\n",
    "\n",
    "*The answers to questions that you care about, such as what algorithm works best on your data or which input features to use, can only be found through the results of experimental trials.*\n",
    "\n",
    "***This is due mainly to the fact that machine learning methods are complex and resist formal methods of analysis.**\"* [Source](https://machinelearningmastery.com/controlled-experiments-in-machine-learning/)\n",
    "\n",
    "Nous avons donc **entrainé plus d'une cinquantaine de modèles** en **testant et modifiant chaque étape du réseau de neurones**, la plupart avaient des résultats médiocres. Le modèle actuel est celui qui a obtenu les meilleurs résultats."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1218b1cd-e3e7-4e7f-8ef5-3bd493d75637",
   "metadata": {},
   "source": [
    "### 1. Construction du modèle\n",
    "\n",
    "Le modèle est composé, comme expliqué plus haut, majoritairement d'une itération de Convolutions2D suivis de MaxPooling, connectés à la fin par un Fully Connected Layer et une fonction de catégorisation softmax permettant d'obtenir un output de probabilités des classes.\n",
    "\n",
    "Voici une fonction d'activation qui donnait de meilleures performances que ReLU que nous avons utilisé dans le modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3b0c556f-a8bb-4998-a9f4-85cbd903a60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mish(x):\n",
    "    # Mish Activation Function\n",
    "    # Mish is a novel activation function proposed by Misra (2019). It is defined as x * tanh(softplus(x)).\n",
    "    # The function aims to provide better performance by facilitating smoother and deeper information propagation without saturation.\n",
    "    # Its non-monotonic nature helps in reducing the risk of dead neurons and encourages a more efficient learning process.\n",
    "    return x * tf.math.tanh(tf.math.softplus(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51e90216-232e-4b63-865d-5e0cf88ee7d9",
   "metadata": {},
   "source": [
    "Et voici la fonction qui construit le modèle:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "360c92ce-a3ed-4154-8ac3-3c9738ae9435",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    # Define the input layer with the shape of the images\n",
    "    # This is the first layer of the network, where we specify the dimensions of the input images (height, width, channels).\n",
    "    # img_size should match the dimensions of the images in your dataset, and '1' indicates grayscale images. For RGB images, this would be 3.\n",
    "    input_img = Input(shape=(img_size, img_size, 1))\n",
    "\n",
    "    # First Convolutional Block\n",
    "    # Convolutional layers are the core building blocks of a CNN. They perform convolution operations, learning features from the input images.\n",
    "    # A 32 filter with a (3,3) kernel size is a common choice for the first layer, aiming to capture basic patterns such as edges and corners.\n",
    "    # Padding=\"same\" ensures the output has the same width and height as the input, providing a way to preserve spatial dimensions after convolution.\n",
    "    x = Conv2D(32, (3, 3), padding=\"same\")(input_img)\n",
    "\n",
    "    # Batch Normalization\n",
    "    # Batch normalization is used to normalize the inputs of each layer. It stabilizes the learning process and dramatically reduces the number of training epochs required to train deep networks.\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    # Activation - Mish\n",
    "    # After normalization, we apply the Mish activation function to introduce non-linearity, allowing the network to learn complex patterns.\n",
    "    # Mish is a novel activation function and provides better performance compared to traditional functions like ReLU or Sigmoid.\n",
    "    x = Activation(mish)(x)\n",
    "\n",
    "    # MaxPooling\n",
    "    # MaxPooling reduces the spatial dimensions (height and width) of the input volume for the next convolutional layer. It helps in reducing computation, and it also helps in extracting robust features.\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "    # Dropout\n",
    "    # Dropout is a regularization technique where randomly selected neurons are ignored during training, reducing the risk of overfitting.\n",
    "    # A rate of 0.25 means 25% of the nodes are dropped out, chosen empirically to balance between regularization and retaining network capacity.\n",
    "    x = Dropout(0.25)(x)\n",
    "\n",
    "    # Subsequent Convolutional Blocks\n",
    "    # Similar blocks are stacked, with increasing filter sizes to capture more complex patterns. A common practice is to double the number of filters, this provided better performance.\n",
    "    # This increase reflects the idea that the higher up we go in the network, the more complex and abstract the features should become.\n",
    "    # The choices of kernel sizes, padding, activation functions, and dropout rates follow the same rationale as above.\n",
    "    filters = [32, 64, 64, 128, 128]\n",
    "    for f in filters:\n",
    "        x = Conv2D(f, (3, 3), padding=\"same\")(x)\n",
    "        x = BatchNormalization()(x)\n",
    "        x = Activation(mish)(x)\n",
    "\n",
    "        # Only apply MaxPooling and Dropout for more complex patterns\n",
    "        # We don't apply MaxPooling and Dropout for the first two blocks to keep the basic features of the image (edges, corners, etc.) intact.\n",
    "        # For the subsequent blocks, we apply MaxPooling and Dropout to reduce the spatial dimensions and prevent overfitting.\n",
    "        # The maxpooling is more effective for larger filter sizes, as they are the ones which require more computation.\n",
    "        if f in [64, 128]:\n",
    "            x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "            x = Dropout(0.25)(x)\n",
    "\n",
    "    # Flatten\n",
    "    # Before connecting to a fully connected (Dense) layer, the feature maps must be flattened into a single vector.\n",
    "    x = Flatten()(x)\n",
    "\n",
    "    # Fully Connected Layer\n",
    "    # Dense layers perform classification based on the features extracted and downsampled by the convolutional and pooling layers.\n",
    "    # A size of 200 neurons is chosen as a balance between model complexity and computational efficiency.\n",
    "    x = Dense(200)(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation(mish)(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Output Layer\n",
    "    # The final layer is a Dense layer with a number of neurons equal to the number of classes in the dataset. Softmax activation is used for multi-class classification.\n",
    "    output = Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    # Model Compilation\n",
    "    # Adam optimizer is used with its default learning rate, which is found to be effective across a variety of tasks.\n",
    "    # The choice of the loss function, categorical_crossentropy, is standard for multi-class classification problems.\n",
    "    model = Model(inputs=input_img, outputs=output)\n",
    "    optimizer = Adam(\n",
    "        learning_rate=2e-3,\n",
    "        beta_1=0.9,\n",
    "        beta_2=0.999,\n",
    "        epsilon=1e-08,\n",
    "        amsgrad=False,\n",
    "    )\n",
    "    model.compile(\n",
    "        optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"]\n",
    "    )\n",
    "\n",
    "    # Model Summary\n",
    "    model.summary()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b4c0b14-087d-4ec2-9527-10f51e7a9f4c",
   "metadata": {},
   "source": [
    "**Et la petite démo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "158286f5-bede-4bbe-a491-388c5591e785",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_5\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_5\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">320</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">70</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │         <span style=\"color: #00af00; text-decoration-color: #00af00\">9,248</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">35</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │        <span style=\"color: #00af00; text-decoration-color: #00af00\">36,928</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)       │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │        <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">8</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │       <span style=\"color: #00af00; text-decoration-color: #00af00\">147,584</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)      │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">102,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │           <span style=\"color: #00af00; text-decoration-color: #00af00\">800</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Activation</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">200</span>)            │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">804</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ input_layer_1 (\u001b[38;5;33mInputLayer\u001b[0m)      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m1\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m320\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation (\u001b[38;5;33mActivation\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m70\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │         \u001b[38;5;34m9,248\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_1           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │           \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_1 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m32\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_3 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m18,496\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_2           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_2 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m35\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_4 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │        \u001b[38;5;34m36,928\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_3           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │           \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_3 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m17\u001b[0m, \u001b[38;5;34m64\u001b[0m)     │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_3 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m64\u001b[0m)       │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_5 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │        \u001b[38;5;34m73,856\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_4           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_4 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m8\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_4 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ conv2d_6 (\u001b[38;5;33mConv2D\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │       \u001b[38;5;34m147,584\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_5           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │           \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_5 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ max_pooling2d_5 (\u001b[38;5;33mMaxPooling2D\u001b[0m)  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m2\u001b[0m, \u001b[38;5;34m128\u001b[0m)      │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten_1 (\u001b[38;5;33mFlatten\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │       \u001b[38;5;34m102,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ batch_normalization_6           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │           \u001b[38;5;34m800\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)            │                        │               │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ activation_6 (\u001b[38;5;33mActivation\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m200\u001b[0m)            │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m)              │           \u001b[38;5;34m804\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">392,428</span> (1.50 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m392,428\u001b[0m (1.50 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">391,132</span> (1.49 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m391,132\u001b[0m (1.49 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,296</span> (5.06 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,296\u001b[0m (5.06 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = build_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73ddb1a2-ac2b-44a3-9302-0e6acae6076d",
   "metadata": {},
   "source": [
    "### 2. Entrainement du modèle\n",
    "\n",
    "Nous pouvons à présent entrainer le modèle. Ci-dessous la fonction responsable.\n",
    "\n",
    "*Le model.fit est intentionnellement commenté car entraîner le modèle prend beaucoup de temps, surtout sans GPU. Nous allons plutôt charger un modèle déjà entraîné.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "92b4ad2c-860f-41b8-b10f-240ca7ea6d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model):\n",
    "    # Data Augmentation\n",
    "    # Data augmentation is crucial for training deep learning models. It helps in making the model robust to slight variations and prevents overfitting.\n",
    "    # The chosen parameters for rotation, zoom, and flips are standard practices to introduce variability in the training data without altering the semantics of the images.\n",
    "    datagen = ImageDataGenerator(\n",
    "        rotation_range=180,\n",
    "        zoom_range=[0.98, 1.02],\n",
    "        width_shift_range=0.1,\n",
    "        height_shift_range=0.1,\n",
    "        horizontal_flip=True,\n",
    "        vertical_flip=True,\n",
    "    )\n",
    "\n",
    "    # Learning Rate Scheduler\n",
    "    # ReduceLROnPlateau reduces the learning rate when a metric has stopped improving, which in this case is the validation loss.\n",
    "    # This helps in fine-tuning the model when it's close to convergence, avoiding overshooting minima due to a high learning rate.\n",
    "    reduce_lr = ReduceLROnPlateau(\n",
    "        monitor=\"val_loss\", factor=0.2, patience=5, min_lr=0.001\n",
    "    )\n",
    "\n",
    "    train_X = train_images\n",
    "    train_y = train_labels\n",
    "\n",
    "    val_X = validation_images\n",
    "    val_y = validation_labels\n",
    "\n",
    "    X_train = train_X.reshape(-1, img_size, img_size, 1)\n",
    "    X_val = val_X.reshape(-1, img_size, img_size, 1)\n",
    "\n",
    "    Y_train = to_categorical(train_y, num_classes=num_classes)\n",
    "    Y_val = to_categorical(val_y, num_classes=num_classes)\n",
    "\n",
    "    print(\"Training model...\")\n",
    "    epochs = 10\n",
    "\n",
    "    \n",
    "    # Add the reduce_lr callback to model.fit()\n",
    "    \"\"\"\n",
    "    UNCOMMENT TO TRAIN THE MODEL\n",
    "    model.fit(\n",
    "        datagen.flow(X_train, Y_train),\n",
    "        epochs=epochs,\n",
    "        validation_data=(X_val, Y_val),\n",
    "        callbacks=[reduce_lr],\n",
    "    )\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"Model trained successfully!\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff726e04-617b-4c41-964a-4821546e62ff",
   "metadata": {},
   "source": [
    "**Et la petite démo:**\n",
    "\n",
    "*Nous chargeons un modèle déjà entrainé pour les raisons mentionnées plus haut.*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d27c7360-7906-432a-8d08-0d6402440a5f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model loaded successfully\n"
     ]
    }
   ],
   "source": [
    "model_path = \"./save/v1.keras\"\n",
    "\n",
    "model = tf.keras.models.load_model(model_path)\n",
    "\n",
    "print(\"Model loaded successfully\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd84991a-5cde-4028-9657-53ae9ce5d90e",
   "metadata": {},
   "source": [
    "### 3. Testing de l'efficacité du modèle\n",
    "\n",
    "Maintenant que le modèle est construit et entraîné, nous pouvons commencer a tester son efficacité et a visualiser les erreurs.\n",
    "\n",
    "Voici la fonction d'évaluation du modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "52663175-fdd5-4167-87ef-af8c3b81f0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model):\n",
    "    # Test the model and build confusion matrix\n",
    "    print(\"Testing model...\")\n",
    "    X_test = test_images.reshape(-1, img_size, img_size, 1)\n",
    "    Y_test = to_categorical(test_labels, num_classes=num_classes)\n",
    "\n",
    "    test_loss, test_acc = model.evaluate(X_test, Y_test)\n",
    "\n",
    "    print(\"Test accuracy:\", test_acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e192eeea-5d4f-4b41-b7f8-65d25049dfc1",
   "metadata": {},
   "source": [
    "**Et sa démo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7627bd36-08db-4c39-9337-15c2e6ca11f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1714337088.177166   25298 service.cc:145] XLA service 0x7f5dc4001d70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1714337088.177235   25298 service.cc:153]   StreamExecutor device (0): NVIDIA GeForce RTX 2080 SUPER, Compute Capability 7.5\n",
      "2024-04-28 22:44:48.196648: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2024-04-28 22:44:48.283569: I external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:465] Loaded cuDNN version 8907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m46/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━━━━━\u001b[0m \u001b[1m0s\u001b[0m 3ms/step - accuracy: 0.9851 - loss: 0.0511 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1714337089.450221   25298 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 17ms/step - accuracy: 0.9821 - loss: 0.0572\n",
      "Test accuracy: 0.9745189547538757\n"
     ]
    }
   ],
   "source": [
    "test_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53f09133-99d5-4294-903c-951ffe2b1f94",
   "metadata": {},
   "source": [
    "**L'accuracy est supérieure à 97% sur notre échantillon de test (que n'a jamais vu notre modèle)**\n",
    "\n",
    "Voici à présent la fonction de visualisation qui contient la matrice de confusion du modèle :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f370980d-659a-4781-a543-525ac4d61840",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_tests(model):\n",
    "    import matplotlib.pyplot as plt\n",
    "    import seaborn as sns\n",
    "    from sklearn.metrics import confusion_matrix  # type: ignore\n",
    "\n",
    "    X_test = test_images.reshape(-1, img_size, img_size, 1)\n",
    "    Y_test = to_categorical(test_labels, num_classes=num_classes)\n",
    "\n",
    "    Y_pred = model.predict(X_test)\n",
    "    Y_pred_classes = np.argmax(Y_pred, axis=1)\n",
    "    Y_true = np.argmax(Y_test, axis=1)\n",
    "\n",
    "    cm = confusion_matrix(Y_true, Y_pred_classes)\n",
    "\n",
    "    sorted_classes = sorted(shape_classes.items(), key=lambda item: item[1])\n",
    "    class_labels = [item[0] for item in sorted_classes]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    ax = sns.heatmap(\n",
    "        cm,\n",
    "        annot=True,\n",
    "        fmt=\"d\",\n",
    "        cmap=\"Blues\",\n",
    "        xticklabels=class_labels,\n",
    "        yticklabels=class_labels,\n",
    "    )\n",
    "    ax.invert_yaxis()\n",
    "    plt.xlabel(\"Predicted Label\")\n",
    "    plt.ylabel(\"True Label\")\n",
    "    plt.title(\"Confusion Matrix\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e65da24c-fe11-4320-b5db-3363860c06c2",
   "metadata": {},
   "source": [
    "**Et sa démo:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "7e3d1e0f-a93f-4057-9a8b-d4299520f498",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m61/61\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxQAAAK9CAYAAAC95yoDAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAB6PElEQVR4nO3deVxV1frH8e8B4YAiowKiouaMIw4paZo5pVaadtOyQjMr08pwynKeKHMqyyE1JdPbbbSrlkNqWg44z0OOYSrOiDgAwv794c9zOeHAOSkb8PPutV8vz9rr7P3s4+7Iw7PWXhbDMAwBAAAAgBNczA4AAAAAQO5FQgEAAADAaSQUAAAAAJxGQgEAAADAaSQUAAAAAJxGQgEAAADAaSQUAAAAAJxGQgEAAADAaSQUAAAAAJxGQgEAN7F//341a9ZMPj4+slgsmjdv3l09/pEjR2SxWDRr1qy7etzc7JFHHtEjjzxidhgAAAeRUADIsQ4ePKhXX31VDzzwgDw8POTt7a169erpo48+0pUrV+7puSMjI7Vjxw6NHDlSs2fPVq1ate7p+bJTp06dZLFY5O3tfdPPcf/+/bJYLLJYLBozZozDxz9+/LiGDBmirVu33oVoAQA5XT6zAwCAm1m4cKH+9a9/yWq16sUXX1TlypWVkpKi33//XX369NGuXbv02Wef3ZNzX7lyRWvXrtV7772nHj163JNzlChRQleuXJGbm9s9Of6d5MuXT5cvX9b8+fP1zDPP2O2bM2eOPDw8dPXqVaeOffz4cQ0dOlQlS5ZU9erVs/y+JUuWOHU+AIC5SCgA5DiHDx9Whw4dVKJECS1fvlxFihSx7evevbsOHDighQsX3rPznz59WpLk6+t7z85hsVjk4eFxz45/J1arVfXq1dO///3vTAnF3Llz1apVK3333XfZEsvly5eVP39+ubu7Z8v5AAB3F0OeAOQ4o0ePVlJSkmbMmGGXTNxQpkwZvfXWW7bX165d0/Dhw1W6dGlZrVaVLFlS7777rpKTk+3eV7JkST3++OP6/fff9eCDD8rDw0MPPPCAvvjiC1ufIUOGqESJEpKkPn36yGKxqGTJkpKuDxW68eeMhgwZIovFYte2dOlS1a9fX76+vvLy8lL58uX17rvv2vbfag7F8uXL9fDDD6tAgQLy9fVV69attWfPnpue78CBA+rUqZN8fX3l4+Ojzp076/Lly7f+YP/mueee088//6yEhARb24YNG7R//34999xzmfqfO3dOvXv3VpUqVeTl5SVvb2+1aNFC27Zts/X59ddfVbt2bUlS586dbUOnblznI488osqVK2vTpk1q0KCB8ufPb/tc/j6HIjIyUh4eHpmuv3nz5vLz89Px48ezfK0AgHuHhAJAjjN//nw98MADeuihh7LU/+WXX9agQYNUo0YNjR8/Xg0bNlR0dLQ6dOiQqe+BAwf09NNPq2nTpho7dqz8/PzUqVMn7dq1S5LUtm1bjR8/XpL07LPPavbs2ZowYYJD8e/atUuPP/64kpOTNWzYMI0dO1ZPPvmkVq9efdv3/fLLL2revLlOnTqlIUOGKCoqSmvWrFG9evV05MiRTP2feeYZXbx4UdHR0XrmmWc0a9YsDR06NMtxtm3bVhaLRd9//72tbe7cuapQoYJq1KiRqf+hQ4c0b948Pf744xo3bpz69OmjHTt2qGHDhrYf7itWrKhhw4ZJkl555RXNnj1bs2fPVoMGDWzHOXv2rFq0aKHq1atrwoQJatSo0U3j++ijj1S4cGFFRkYqLS1NkjR16lQtWbJEEydOVEhISJavFQBwDxkAkINcuHDBkGS0bt06S/23bt1qSDJefvllu/bevXsbkozly5fb2kqUKGFIMlatWmVrO3XqlGG1Wo1evXrZ2g4fPmxIMj788EO7Y0ZGRholSpTIFMPgwYONjF+n48ePNyQZp0+fvmXcN84xc+ZMW1v16tWNwMBA4+zZs7a2bdu2GS4uLsaLL76Y6XwvvfSS3TGfeuopIyAg4JbnzHgdBQoUMAzDMJ5++mmjcePGhmEYRlpamhEcHGwMHTr0pp/B1atXjbS0tEzXYbVajWHDhtnaNmzYkOnabmjYsKEhyZgyZcpN9zVs2NCubfHixYYkY8SIEcahQ4cMLy8vo02bNne8RgBA9qFCASBHSUxMlCQVLFgwS/1/+uknSVJUVJRde69evSQp01yLsLAwPfzww7bXhQsXVvny5XXo0CGnY/67G3MvfvzxR6Wnp2fpPSdOnNDWrVvVqVMn+fv729qrVq2qpk2b2q4zo9dee83u9cMPP6yzZ8/aPsOseO655/Trr78qPj5ey5cvV3x8/E2HO0nX5124uFz/ZyMtLU1nz561DefavHlzls9ptVrVuXPnLPVt1qyZXn31VQ0bNkxt27aVh4eHpk6dmuVzAQDuPRIKADmKt7e3JOnixYtZ6v/nn3/KxcVFZcqUsWsPDg6Wr6+v/vzzT7v20NDQTMfw8/PT+fPnnYw4s/bt26tevXp6+eWXFRQUpA4dOujrr7++bXJxI87y5ctn2lexYkWdOXNGly5dsmv/+7X4+flJkkPX0rJlSxUsWFD/+c9/NGfOHNWuXTvTZ3lDenq6xo8fr7Jly8pqtapQoUIqXLiwtm/frgsXLmT5nEWLFnVoAvaYMWPk7++vrVu36uOPP1ZgYGCW3wsAuPdIKADkKN7e3goJCdHOnTsdet/fJ0Xfiqur603bDcNw+hw3xvff4OnpqVWrVumXX37RCy+8oO3bt6t9+/Zq2rRppr7/xD+5lhusVqvatm2rmJgY/fDDD7esTkjSqFGjFBUVpQYNGujLL7/U4sWLtXTpUlWqVCnLlRjp+ufjiC1btujUqVOSpB07djj0XgDAvUdCASDHefzxx3Xw4EGtXbv2jn1LlCih9PR07d+/36795MmTSkhIsD2x6W7w8/OzeyLSDX+vgkiSi4uLGjdurHHjxmn37t0aOXKkli9frhUrVtz02Dfi3LdvX6Z9e/fuVaFChVSgQIF/dgG38Nxzz2nLli26ePHiTSey3/Dtt9+qUaNGmjFjhjp06KBmzZqpSZMmmT6TrCZ3WXHp0iV17txZYWFheuWVVzR69Ght2LDhrh0fAPDPkVAAyHH69u2rAgUK6OWXX9bJkycz7T948KA++ugjSdeH7EjK9CSmcePGSZJatWp11+IqXbq0Lly4oO3bt9vaTpw4oR9++MGu37lz5zK998YCb39/lO0NRYoUUfXq1RUTE2P3A/rOnTu1ZMkS23XeC40aNdLw4cP1ySefKDg4+Jb9XF1dM1U/vvnmGx07dsyu7Ubic7Pky1H9+vVTXFycYmJiNG7cOJUsWVKRkZG3/BwBANmPhe0A5DilS5fW3Llz1b59e1WsWNFupew1a9bom2++UadOnSRJ1apVU2RkpD777DMlJCSoYcOGWr9+vWJiYtSmTZtbPpLUGR06dFC/fv301FNP6c0339Tly5c1efJklStXzm5S8rBhw7Rq1Sq1atVKJUqU0KlTpzRp0iQVK1ZM9evXv+XxP/zwQ7Vo0UIRERHq0qWLrly5ookTJ8rHx0dDhgy5a9fxdy4uLhowYMAd+z3++OMaNmyYOnfurIceekg7duzQnDlz9MADD9j1K126tHx9fTVlyhQVLFhQBQoUUJ06dVSqVCmH4lq+fLkmTZqkwYMH2x5jO3PmTD3yyCMaOHCgRo8e7dDxAAD3BhUKADnSk08+qe3bt+vpp5/Wjz/+qO7du+udd97RkSNHNHbsWH388ce2vtOnT9fQoUO1YcMG9ezZU8uXL1f//v311Vdf3dWYAgIC9MMPPyh//vzq27evYmJiFB0drSeeeCJT7KGhofr888/VvXt3ffrpp2rQoIGWL18uHx+fWx6/SZMmWrRokQICAjRo0CCNGTNGdevW1erVqx3+YfxeePfdd9WrVy8tXrxYb731ljZv3qyFCxeqePHidv3c3NwUExMjV1dXvfbaa3r22We1cuVKh8518eJFvfTSSwoPD9d7771na3/44Yf11ltvaezYsVq3bt1duS4AwD9jMRyZvQcAAAAAGVChAAAAAOA0EgoAAAAATiOhAAAAAOA0EgoAAAAATiOhAAAAAOA0EgoAAAAATiOhAAAAAOC0PLlS9pVUsyPA/cJiMTsCALi7Jqw6aHYIuE+882hps0O4Jc/wHqad+8qWT0w7t7OoUAAAAABwWp6sUAAAAABOs/A7d0fwaQEAAABwGgkFAAAAAKcx5AkAAADIiKeuOIQKBQAAAACnUaEAAAAAMmJStkP4tAAAAAA4jQoFAAAAkBFzKBxChQIAAACA00goAAAAADiNIU8AAABARkzKdgifFgAAAACnUaEAAAAAMmJStkOoUAAAAAC5UFpamgYOHKhSpUrJ09NTpUuX1vDhw2UYhq2PYRgaNGiQihQpIk9PTzVp0kT79++3O865c+fUsWNHeXt7y9fXV126dFFSUlKW4yChAAAAAHKhDz74QJMnT9Ynn3yiPXv26IMPPtDo0aM1ceJEW5/Ro0fr448/1pQpUxQbG6sCBQqoefPmunr1qq1Px44dtWvXLi1dulQLFizQqlWr9Morr2Q5DouRMYXJI66kmh0B7hdURAHkNRNWHTQ7BNwn3nm0tNkh3JJn3X6mnfvKug+y3Pfxxx9XUFCQZsyYYWtr166dPD099eWXX8owDIWEhKhXr17q3bu3JOnChQsKCgrSrFmz1KFDB+3Zs0dhYWHasGGDatWqJUlatGiRWrZsqb/++kshISF3jIMKBQAAAJBDJCcnKzEx0W5LTk6+ad+HHnpIy5Yt0x9//CFJ2rZtm37//Xe1aNFCknT48GHFx8erSZMmtvf4+PioTp06Wrt2rSRp7dq18vX1tSUTktSkSRO5uLgoNjY2SzGTUAAAAAAZWSymbdHR0fLx8bHboqOjbxrmO++8ow4dOqhChQpyc3NTeHi4evbsqY4dO0qS4uPjJUlBQUF27wsKCrLti4+PV2BgoN3+fPnyyd/f39bnTnjKEwAAAJBD9O/fX1FRUXZtVqv1pn2//vprzZkzR3PnzlWlSpW0detW9ezZUyEhIYqMjMyOcCWRUAAAAAD2TFzYzmq13jKB+Ls+ffrYqhSSVKVKFf3555+Kjo5WZGSkgoODJUknT55UkSJFbO87efKkqlevLkkKDg7WqVOn7I577do1nTt3zvb+O2HIEwAAAJALXb58WS4u9j/Ou7q6Kj09XZJUqlQpBQcHa9myZbb9iYmJio2NVUREhCQpIiJCCQkJ2rRpk63P8uXLlZ6erjp16mQpDioUAAAAQC70xBNPaOTIkQoNDVWlSpW0ZcsWjRs3Ti+99JIkyWKxqGfPnhoxYoTKli2rUqVKaeDAgQoJCVGbNm0kSRUrVtRjjz2mrl27asqUKUpNTVWPHj3UoUOHLD3hSSKhAAAAAOzlkufCT5w4UQMHDtTrr7+uU6dOKSQkRK+++qoGDRpk69O3b19dunRJr7zyihISElS/fn0tWrRIHh4etj5z5sxRjx491LhxY7m4uKhdu3b6+OOPsxwH61AA/0Au+b4BgCxjHQpklxy9DkW990w795XVI007t7OoUAAAAAAZmTgpOzfi0wIAAADgNBIKAAAAAE5jyBMAAACQEZMkHUKFAgAAAIDTqFAAAAAAGTEp2yF8WgAAAACcRoUCAAAAyIgKhUP4tAAAAAA4jYQCAAAAgNMY8gQAAABk5MJjYx1BhQIAAACA06hQAAAAABkxKdshfFoAAAAAnEZCAQAAAMBpDHkCAAAAMrIwKdsRVCgAAAAAOI0KBQAAAJARk7IdwqcFAAAAwGlUKAAAAICMmEPhECoUAAAAAJxGQgEAAADAaQx5AgAAADJiUrZD+LQAAAAAOI0KBQAAAJARk7IdQoUCAAAAgNNyVEJx9epVs0MAAAAA4ADTE4r09HQNHz5cRYsWlZeXlw4dOiRJGjhwoGbMmGFydAAAALjvWFzM23Ih06MeMWKEZs2apdGjR8vd3d3WXrlyZU2fPt3EyAAAAADciekJxRdffKHPPvtMHTt2lKurq629WrVq2rt3r4mRAQAA4L5ksZi35UKmJxTHjh1TmTJlMrWnp6crNTXVhIgAAAAAZJXpCUVYWJh+++23TO3ffvutwsPDTYgIAAAA9zXmUDjE9HUoBg0apMjISB07dkzp6en6/vvvtW/fPn3xxRdasGCB2eEBAAAAuA3T06DWrVtr/vz5+uWXX1SgQAENGjRIe/bs0fz589W0aVOzwwMAAABwG6ZXKCTp4Ycf1tKlS80OAwAAAMi1k6PNYnqFAgAAAEDuZUqFws/PT5YsZn7nzp27x9EAAAAAGeTSydFmMSWhmDBhghmnBQAAAHCXmZJQREZGmnFaAAAAAHeZ6ZOyExMTb9pusVhktVrl7u6ezREBAADgvsaQJ4eYnlD4+vredj5FsWLF1KlTJw0ePFguLvzlAgAAADmJ6QnFrFmz9N5776lTp0568MEHJUnr169XTEyMBgwYoNOnT2vMmDGyWq169913TY4WAAAAeR6PjXWI6QlFTEyMxo4dq2eeecbW9sQTT6hKlSqaOnWqli1bptDQUI0cOZKEAgAAAMhhTB9DtGbNGoWHh2dqDw8P19q1ayVJ9evXV1xcXHaHBgAAAOAOTE8oihcvrhkzZmRqnzFjhooXLy5JOnv2rPz8/LI7NAAAANyPLC7mbbmQ6UOexowZo3/961/6+eefVbt2bUnSxo0btXfvXn377beSpA0bNqh9+/ZmhpknTf50oqZO/sSurWSpUpo3f5FJESGv+2ruHMXMnKEzZ06rXPkKeufdgapStarZYSEP4l7DP7V35ULt/W2hks6elCT5Fimh6i2fVbHK139W+XlcP8Xv32H3nvIPt9BDz71he336yB/aNG+mzsYdkGRRoZLlVLvtS/Iv9kC2XQeQHUxPKJ588knt3btXU6dO1R9//CFJatGihebNm6eSJUtKkrp162ZihHlb6TJlNXX6TNtrV1dXE6NBXrbo5580ZnS0BgweqipVqmnO7Bh1e7WLflywSAEBAWaHhzyEew13Q36/QqrZprO8A0Mkw9CBdcu0bMpwPfnuRPmFlJAklav/mMIff972nnzuHrY/p169oqWfDFTxqnUU0aG70tPTtGXBl1oycaCeGRUjF1fTfwTD7TAp2yE54m4uVaqU3n//fbPDuC+5urqqUKHCZoeB+8DsmJlq+/QzavNUO0nSgMFDtWrVr5r3/Xfq0vUVk6NDXsK9hrshtGodu9c1W0dq76qFOn14ry2hyOdmVX4f/5u+/8LJo0q+dFHhj78gL//r/85Wb/WcfhzRXUlnT11PVIA8IkckFAkJCVq/fr1OnTql9PR0u30vvviiSVHdH+Li/lTTRvXlbrWqarXqerNnLxUpwpcc7q7UlBTt2b1LXbq+amtzcXFR3boPafu2LSZGhryGew33Qnp6mo5s+l3XUq4q8IGKtvaDG1bo4PoV8vT2U/GqD6p6y2dtVQqfoGKyFvDW/jWLVfWx9jLS07V/9RL5BBeXV0CQWZeCrMqlcxnMYnpCMX/+fHXs2FFJSUny9va2W+TOYrGQUNxDVapW1bAR0SpZspTOnDmtKZM+1UsvdtS38+arQAEvs8NDHnI+4bzS0tIyDTcJCAjQ4cOHTIoKeRH3Gu6mc8cOa+GHvZSWmiI3q6cefXWgfIuESpIeqP2IvAIC5enjr/PHjmjjD5/rwsljavzqAEmSm0d+tXj7fS2bOlzbfvpKkuQdGKJmbwyXC8OLkceYnlD06tVLL730kkaNGqX8+fM7/P7k5GQlJyfbtaW7WGW1Wu9WiHlW/Ycb2v5crnwFVa5STS2bNdKSRT/rqXb/MjEyAADM5xNUTK3f/UQpVy7pyJbf9VvMWLWMGi3fIqEq/3ALWz//oqXk6e2nxR+9q8TTJ+RduIiupSTr9y8nKPCBMDV8qZ+M9HTt/OU7Lf10iJ54Z4LyufNzCvIO0+s5x44d05tvvulUMiFJ0dHR8vHxsds+/CD6Lkd5f/D29lZoiZI6ypofuMv8fP3k6uqqs2fP2rWfPXtWhQoVMikq5EXca7ibXPO5yTswRIVKlFWtNp3lX/QB7Vr+4037Fi5VQZJ08fRxSdKhDb8q6ewpPfzi2ypcspwCH6ighi/1VdLZeMVtW5dt1wAnWSzmbbmQ6QlF8+bNtXHjRqff379/f124cMFu69Ov/12M8P5x+fIl/XX0qAoVZpI27i43d3dVDKuk2HVrbW3p6emKjV2rqtUyL2wJOIt7DfeSYaQr/VrqTfed++ugJMnT+/ok7WspydeHcdsN5XaRLBYZRvpNjwHkVqYPeWrVqpX69Omj3bt3q0qVKnJzc7Pb/+STT972/VZr5uFNV27+/zr+ZtyHH6jBI41UJCREp0+d0uRPJ8rV1UWPtXzc7NCQB70Q2VkD3+2nSpUqq3KVqvpydoyuXLmiNk+1NTs05DHca7gbNs6bqWKVaqmAf6BSr17WoQ2/Kn7/DjV7Y7gST5/QoQ0rVKxSbVm9vHX+r8Na/+1nCipbWf7FSkmSQiqGa+P3M7Tuq0mq+MgTMgxDOxZ/LRcXVxUpX83kq8OdWHJppcAspicUXbt2lSQNGzYs0z6LxaK0tLTsDum+cfJkvPr3jVJCQoL8/P0VHl5TX8z5Wv7+N38EHvBPPNaipc6fO6dJn3ysM2dOq3yFipo0dboCGIaCu4x7DXfD1YsX9NussbqceE7uHgXkV7SUmr0xXEUr1lDSudM6vnerdi//UdeSryq/X2GVCK+nai2etb3fN7i4Gr8+WFsXztXCD3tJFosCipdW0x7Db/moWSC3shiGYZgdxN1GhQLZhV9gAMhrJqw6aHYIuE+882hps0O4pfztPjft3Je/e8m0czvL9AoFAAAAkJMw5MkxOSKhuHTpklauXKm4uDilpKTY7XvzzTdNigoAAADAnZieUGzZskUtW7bU5cuXdenSJfn7++vMmTPKnz+/AgMDSSgAAACQvShQOMT0x8a+/fbbeuKJJ3T+/Hl5enpq3bp1+vPPP1WzZk2NGTPG7PAAAAAA3IbpCcXWrVvVq1cvubi4yNXVVcnJySpevLhGjx6td9991+zwAAAAcJ+xWCymbbmR6QmFm5ubXFyuhxEYGKi4/1+l2cfHR0ePHjUzNAAAAAB3YPocivDwcG3YsEFly5ZVw4YNNWjQIJ05c0azZ89W5cqVzQ4PAAAAwG2YXqEYNWqUihQpIkkaOXKk/Pz81K1bN50+fVqfffaZydEBAADgfsOQJ8eYnlDUqlVLjRo1knR9yNOiRYuUmJioTZs2qVo1lqYHAAAAbqZkyZI3TUq6d+8uSbp69aq6d++ugIAAeXl5qV27djp58qTdMeLi4tSqVSvbE1b79Omja9euORSH6UOeAAAAgJwkt1QKNmzYoLS0NNvrnTt3qmnTpvrXv/4l6frTVBcuXKhvvvlGPj4+6tGjh9q2bavVq1dLktLS0tSqVSsFBwdrzZo1OnHihF588UW5ublp1KhRWY7DYhiGcXcv7c5q1KihZcuWyc/PT+Hh4bf9S9u8ebPDx7+S+k+iA7Iul3zfAECWTVh10OwQcJ9459HSZodwS94dvjDt3Ilfvej0e3v27KkFCxZo//79SkxMVOHChTV37lw9/fTTkqS9e/eqYsWKWrt2rerWrauff/5Zjz/+uI4fP66goCBJ0pQpU9SvXz+dPn1a7u7uWTqvKRWK1q1by2q1SpLatGljRggAAABAjpOcnKzk5GS7NqvVavvZ+VZSUlL05ZdfKioqShaLRZs2bVJqaqqaNGli61OhQgWFhobaEoq1a9eqSpUqtmRCkpo3b65u3bpp165dCg8Pz1LMpiQUgwcPlnS9zNKoUSNVrVpVvr6+ZoQCAAAA2DFzyFN0dLSGDh1q1zZ48GANGTLktu+bN2+eEhIS1KlTJ0lSfHy83N3dM/2MHRQUpPj4eFufjMnEjf039mWVqXMoXF1d1axZM+3Zs4eEAgAAAPe9/v37Kyoqyq7tTtUJSZoxY4ZatGihkJCQexXaLZk+Kbty5co6dOiQSpUqZXYoAAAAgGTiHMmsDG/6uz///FO//PKLvv/+e1tbcHCwUlJSlJCQYPeL+5MnTyo4ONjWZ/369XbHuvEUqBt9ssL0x8aOGDFCvXv31oIFC3TixAklJibabQAAAABubebMmQoMDFSrVq1sbTVr1pSbm5uWLVtma9u3b5/i4uIUEREhSYqIiNCOHTt06tQpW5+lS5fK29tbYWFhWT6/6RWKli1bSpKefPJJu/FqhmHIYrHYPQoLAAAAuNdyy2NjJSk9PV0zZ85UZGSk8uX734/2Pj4+6tKli6KiouTv7y9vb2+98cYbioiIUN26dSVJzZo1U1hYmF544QWNHj1a8fHxGjBggLp37+5QlcT0hGLmzJkqXry4XF1d7drT09MVFxdnUlQAAABAzvfLL78oLi5OL730UqZ948ePl4uLi9q1a6fk5GQ1b95ckyZNsu13dXXVggUL1K1bN0VERKhAgQKKjIzUsGHDHIrBlHUoMnJ1ddWJEycUGBho13727FkFBgY6VaFgHQpkl1z0CwwAyBLWoUB2ycnrUPh2/NK0cyfMed60czvL9ArFjaFNf5eUlCQPDw8TIgIAAMD9LDcNecoJTEsobjwOy2KxaODAgcqfP79tX1pammJjY1W9enWTogMAAACQFaYlFFu2bJF0vUKxY8cOu6W93d3dVa1aNfXu3dus8AAAAHCfokLhGNMSihUrVkiSOnfurI8++kje3t5mhQIAAADASabPoZg5c6bZIQAAAABwkukJBQAAAJCTMOTJMaavlA0AAAAg96JCAQAAAGREgcIhVCgAAAAAOI0KBQAAAJABcygcQ4UCAAAAgNNIKAAAAAA4jSFPAAAAQAYMeXIMFQoAAAAATqNCAQAAAGRAhcIxVCgAAAAAOI2EAgAAAIDTGPIEAAAAZMSIJ4dQoQAAAADgNCoUAAAAQAZMynYMFQoAAAAATqNCAQAAAGRAhcIxVCgAAAAAOI2EAgAAAIDTGPIEAAAAZMCQJ8dQoQAAAADgNCoUAAAAQAZUKBxDhQIAAACA00goAAAAADiNIU8AAABARox4cggVCgAAAABOo0IBAAAAZMCkbMdQoQAAAADgNCoUAAAAQAZUKBxDhQIAAACA00goAAAAADiNIU8AAABABgx5cgwVCgAAAABOo0IBAAAAZESBwiFUKAAAAAA4jYQCAAAAgNMY8gQAAABkwKRsx1ChAAAAAOA0KhQAAABABlQoHEOFAgAAAIDTSCgAAAAAOI0hTwAAAEAGDHlyDBUKAAAAAE6jQgEAAABkQIXCMVQoAAAAADiNCgUAAACQEQUKh1ChAAAAAOA0EgoAAAAATsuTQ55S09LNDgH3Cfd85OTIHjNij5gdAu4TPRuUNjsEwHRMynYMPw0BAAAAcFqerFAAAAAAzqJC4RgqFAAAAACcRkIBAAAAwGkMeQIAAAAyYMSTY6hQAAAAAHAaFQoAAAAgAyZlO4YKBQAAAACnUaEAAAAAMqBA4RgqFAAAAEAudezYMT3//PMKCAiQp6enqlSpoo0bN9r2G4ahQYMGqUiRIvL09FSTJk20f/9+u2OcO3dOHTt2lLe3t3x9fdWlSxclJSVlOQYSCgAAACAXOn/+vOrVqyc3Nzf9/PPP2r17t8aOHSs/Pz9bn9GjR+vjjz/WlClTFBsbqwIFCqh58+a6evWqrU/Hjh21a9cuLV26VAsWLNCqVav0yiuvZDkOi2EYxl29shwg8Wq62SHgPuGej5wc2WNG7BGzQ8B9okudkmaHgPuERw4eeF++32LTzr3vg+ZZ7vvOO+9o9erV+u2332663zAMhYSEqFevXurdu7ck6cKFCwoKCtKsWbPUoUMH7dmzR2FhYdqwYYNq1aolSVq0aJFatmypv/76SyEhIXeMg5+GAAAAgBwiOTlZiYmJdltycvJN+/73v/9VrVq19K9//UuBgYEKDw/XtGnTbPsPHz6s+Ph4NWnSxNbm4+OjOnXqaO3atZKktWvXytfX15ZMSFKTJk3k4uKi2NjYLMVMQgEAAABkYLGYt0VHR8vHx8dui46Ovmmchw4d0uTJk1W2bFktXrxY3bp105tvvqmYmBhJUnx8vCQpKCjI7n1BQUG2ffHx8QoMDLTbny9fPvn7+9v63EkOLjYBAAAA95f+/fsrKirKrs1qtd60b3p6umrVqqVRo0ZJksLDw7Vz505NmTJFkZGR9zzWG6hQAAAAADmE1WqVt7e33XarhKJIkSIKCwuza6tYsaLi4uIkScHBwZKkkydP2vU5efKkbV9wcLBOnTplt//atWs6d+6crc+dkFAAAAAAGbi4WEzbHFGvXj3t27fPru2PP/5QiRIlJEmlSpVScHCwli1bZtufmJio2NhYRURESJIiIiKUkJCgTZs22fosX75c6enpqlOnTpbiYMgTAAAAkAu9/fbbeuihhzRq1Cg988wzWr9+vT777DN99tlnkiSLxaKePXtqxIgRKlu2rEqVKqWBAwcqJCREbdq0kXS9ovHYY4+pa9eumjJlilJTU9WjRw916NAhS094kkgoAAAAADu5ZaXs2rVr64cfflD//v01bNgwlSpVShMmTFDHjh1tffr27atLly7plVdeUUJCgurXr69FixbJw8PD1mfOnDnq0aOHGjduLBcXF7Vr104ff/xxluNgHQrgH2AdCmQX1qFAdmEdCmSXnLwORaX3lph27l0jm5l2bmfl4L9KAAAAIPtZckuJIofg16sAAAAAnEZCAQAAAMBpDHkCAAAAMmDEk2OoUAAAAABwGhUKAAAAIAMmZTuGCgUAAAAAp5FQAAAAAHAaQ54AAACADBjy5BgqFAAAAACcRoUCAAAAyIAChWOoUAAAAABwGhUKAAAAIAPmUDiGCgUAAAAAp5FQAAAAAHAaQ54AAACADBjx5BgqFAAAAACcRoUCAAAAyIBJ2Y6hQgEAAADAaSQUAAAAAJzGkCcAAAAgA0Y8OYYKBQAAAACnUaEAAAAAMmBStmOoUAAAAABwGhUKAAAAIAMKFI6hQgEAAADAaTkuobh69arZIQAAAADIohyRUKSnp2v48OEqWrSovLy8dOjQIUnSwIEDNWPGDJOjAwAAwP3EYrGYtuVGOSKhGDFihGbNmqXRo0fL3d3d1l65cmVNnz7dxMgAAAAA3E6OSCi++OILffbZZ+rYsaNcXV1t7dWqVdPevXtNjAwAAAD3G4vFvC03yhEJxbFjx1SmTJlM7enp6UpNTTUhIgAAAABZkSMSirCwMP3222+Z2r/99luFh4ebEBEAAACArMgR61AMGjRIkZGROnbsmNLT0/X9999r3759+uKLL7RgwQKzwwMAAMB9JLdOjjZLjqhQtG7dWvPnz9cvv/yiAgUKaNCgQdqzZ4/mz5+vpk2bmh0eAAAAgFvIERUKSXr44Ye1dOlSs8MAAADAfY4ChWNyRIUCAAAAQO5kWoXCz88vy+PTzp07d4+jAQAAAK5jDoVjTEsoJkyYYNapAQAAANwlpiUUkZGRZp0aAAAAwF2SIyZlJyYm3rTdYrHIarXK3d09myMCAADA/YoRT47JEQmFr6/vbceqFStWTJ06ddLgwYPl4sI8cgAAACCnyBEJxaxZs/Tee++pU6dOevDBByVJ69evV0xMjAYMGKDTp09rzJgxslqtevfdd02OFgAAAHkZk7IdkyMSipiYGI0dO1bPPPOMre2JJ55QlSpVNHXqVC1btkyhoaEaOXIkCQUAAACQg+SI8UNr1qxReHh4pvbw8HCtXbtWklS/fn3FxcVld2gAAAAAbiNHJBTFixfXjBkzMrXPmDFDxYsXlySdPXtWfn5+2R0aAAAA7jMWi8W0LTfKEUOexowZo3/961/6+eefVbt2bUnSxo0btXfvXn377beSpA0bNqh9+/ZmhgkAAADgb3JEQvHkk09q7969mjp1qv744w9JUosWLTRv3jyVLFlSktStWzcTIwQAAMD9IpcWCkyTIxIKSSpVqpTef/99s8MAAAAA4IAck1AkJCRo/fr1OnXqlNLT0+32vfjiiyZFBQAAAOB2ckRCMX/+fHXs2FFJSUny9va2m5BisVhIKAAAAJBtcuvkaLPkiISiV69eeumllzRq1Cjlz5/f7HDyrJkzPtOKZUv15+FDslo9VLV6uHr07KWSJUvZ+vx1NE4fjR2trVs3KzUlRRH1Hlbvd95TQEAhEyNHXvHV3DmKmTlDZ86cVrnyFfTOuwNVpWpVs8NCLrJ9xXztWLFQiWdOSpICipbQg090VMmq1x/osTzmI8Xt3qJLCWflZvVUkTIVVe9fXeRfJNR2jItnT2nF7In6a+82uVk9VLFeUz3U7iW5uLqack3I3fheA3LIY2OPHTumN998k2TiHtu8cYP+1f45fT77K30ydYauXUvVG6910ZXLlyVJVy5fVo/XXpYsFk2eNkvTY+YqNTVVUW+8nmkYGuCoRT//pDGjo/Xq69311Tc/qHz5Cur2ahedPXvW7NCQi3j5FVa9p1/Ss4M/UYdBE1WsQjUtmDhEZ48dkSQFliirpi/10gsjp6lNr5GSpHlj31V6epokKT09Tf+dMFBp11L1r3fHq2mXPtr9+1Ktmxdj1iUhF+N7Le+yWMzbcqMckVA0b95cGzduNDuMPG/i5Gl6ovVTKl2mrMqVr6DBw6IVf+KE9uzZJUnatnWLThw/psHDo1WmbDmVKVtOQ4ZHa8/undqwfp3J0SO3mx0zU22ffkZtnmqn0mXKaMDgofLw8NC8778zOzTkIg9Ur6uSVR+Ub1BR+QUX00PtOsvNw0PxB/dKkio/0lJFy1eRd6FgBZYoq4inIpV07rStohG3c7POHY9T8679VDi0tEpWra2Ip17U9uXzlXYt1cxLQy7E9xpwXY4Y8tSqVSv16dNHu3fvVpUqVeTm5ma3/8knnzQpsrwtKemiJMnb20eSlJKSIovFInd3d1sfd6tVLi4u2rZls+rUfciUOJH7paakaM/uXerS9VVbm4uLi+rWfUjbt20xMTLkZunpaTqw4TelJicruHTFTPtTk69q9+9L5F0oWAX9C0uS4g/uVkCxksrv87+FUkMr19KK2RN19tifCixRJtviR+7G91rexhwKx+SIhKJr166SpGHDhmXaZ7FYlJaWlt0h5Xnp6ekaNzpa1arXUJmy5SRJVapWk4enpyZOGKPub7wtwzD0yUfjlJaWpjOnT5scMXKz8wnnlZaWpoCAALv2gIAAHT58yKSokFud+euwvhnZU9dSU+Rm9dTjPQYpoGgJ2/7ty+dr9TfTlZp8VX7BxdSmd7Rc813/RdWlC+eV39vP7nj5vX0lSZcvnM+2a0Dux/ca8D85YshTenr6Lbc7JRPJyclKTEy025KTk7Mp8txr9KhhOnhwv0aOHmtr8/P31/sfTtBvK39Vg4iaalT/QV28mKgKFcPk4kKmDiBn8AsupmeHTFL7AR+rSqPHtWT6GJ099qdtf/m6j+rZIZPUrt8Y+QYX08+TR+paaoqJEQNA3pYjEop/Ijo6Wj4+PnbbuA9ZIO92Ro8art9WrdTkaTEKCgq221f3oXqat3CJlqxYraW/rtGwUaN16tQpFS1W3KRokRf4+frJ1dU100TFs2fPqlAhniAGx7jmc5NvUFEFliyrek+/pMLFS2nbL/Ns+635C8g3qKiKlq+ilq8P0PkTR3Vw02pJUgEfP11OtK9EXE5MkCS7YVDAnfC9lrcxKdsxOWLIkyRdunRJK1euVFxcnFJS7H+T9Oabb97yff3791dUVJRdW7Lhdove9zfDMPRh9Aj9uvwXTZkRo6LFit2yr6/f9X9YN8Su0/lzZ/XwI49mV5jIg9zc3VUxrJJi163Vo42bSLpemYyNXasOzz5vcnTI7QzDuOWEasMwJMm2P7h0mDYs+EqXExNsQ52O7tosd8/88g8JvekxgJvhew34nxyRUGzZskUtW7bU5cuXdenSJfn7++vMmTPKnz+/AgMDb5tQWK1WWa1Wu7bEqzzi9GY+GDVMi39eqDETPlH+AgV05sz1eRFeXgXl4eEhSfrvvO9V6oEH5Ofnr+3btmrc6FF69vlIu7UqAGe8ENlZA9/tp0qVKqtylar6cnaMrly5ojZPtTU7NOQiq7/9XCWr1FbBgMJKuXpF+9at0F/7tqtN1EhdOHVCf2xYqRKVasqzoI+Szp/Wxp++Vj43d5Ws+qAkKbRyDfmHhGrJtNGq968uupx4Xmt/mKWqjz6hfG7udzg7YI/vtbzLJbeWCkySIxKKt99+W0888YSmTJkiHx8frVu3Tm5ubnr++ef11ltvmR1envHd119Jkl7rEmnXPmjYKD3R+ilJ0p9HDuvTj8cr8cIFhYSEqPPLr+m5FyIzHQtw1GMtWur8uXOa9MnHOnPmtMpXqKhJU6crgKEBcMCVxAQtmf6hLl04J6tnfhUqVkptokYqtFJNJZ0/q+N/7NTWpT8o+VKS8nv7qmj5KvrXu+Nt1QgXF1c98dYwrZg9Ud+Melv53D1UsV4T1W3D9xwcx/cacJ3FuFEPNpGvr69iY2NVvnx5+fr6au3atapYsaJiY2MVGRmpvXv3OnQ8KhTILu75cv00JOQSM2KPmB0C7hNd6pQ0OwTcJzxyxK+1b67pJ+atv7W0R13Tzu2sHPHTkJubm1xcrocSGBiouLg4SZKPj4+OHj1qZmgAAAC4zzAp2zE5IjcMDw/Xhg0bVLZsWTVs2FCDBg3SmTNnNHv2bFWuXNns8AAAAADcQo6oUIwaNUpFihSRJI0cOVJ+fn7q1q2bTp8+ralTp5ocHQAAAO4nFovFtC03yhEJRa1atdSoUSNJ14c8LVq0SImJidq0aZOqV69ubnAAAABADjRkyJBMCUmFChVs+69evaru3bsrICBAXl5eateunU6ePGl3jLi4OLVq1cr2dNU+ffro2rVrDsWRIxKKRx99VAkJCZnaExMT9eijrH8AAACA7ONiMW9zVKVKlXTixAnb9vvvv9v2vf3225o/f76++eYbrVy5UsePH1fbtv97rHFaWppatWqllJQUrVmzRjExMZo1a5YGDRrkUAw5Yg7Fr7/+mmkxO+l6VvXbb7+ZEBEAAACQ8+XLl0/BwcGZ2i9cuKAZM2Zo7ty5tl/Qz5w5UxUrVtS6detUt25dLVmyRLt379Yvv/yioKAgVa9eXcOHD1e/fv00ZMgQubtnbX0eUxOK7du32/68e/duxcfH216npaVp0aJFKlq0qBmhAQAAANkuOTlZycnJdm03W8j5hv379yskJEQeHh6KiIhQdHS0QkNDtWnTJqWmpqpJkya2vhUqVFBoaKjWrl2runXrau3atapSpYqCgoJsfZo3b65u3bpp165dCg8Pz1LMpiYU1atXt433utnQJk9PT02cONGEyAAAAHC/MnNydHR0tIYOHWrXNnjwYA0ZMiRT3zp16mjWrFkqX768Tpw4oaFDh+rhhx/Wzp07FR8fL3d3d/n6+tq9JygoyPZL/Pj4eLtk4sb+G/uyytSE4vDhwzIMQw888IDWr1+vwoUL2/a5u7srMDBQrq6uJkYIAAAAZJ/+/fsrKirKru1W1YkWLVrY/ly1alXVqVNHJUqU0Ndffy1PT897GmdGpiYUJUqUkCSlp7OyNQAAAHIGM5/eervhTXfi6+urcuXK6cCBA2ratKlSUlKUkJBgV6U4efKkbc5FcHCw1q9fb3eMG0+Butm8jFvJEU95io6O1ueff56p/fPPP9cHH3xgQkQAAABA7pKUlKSDBw+qSJEiqlmzptzc3LRs2TLb/n379ikuLk4RERGSpIiICO3YsUOnTp2y9Vm6dKm8vb0VFhaW5fPmiIRi6tSpds/MvaFSpUqaMmWKCREBAAAAOVvv3r21cuVKHTlyRGvWrNFTTz0lV1dXPfvss/Lx8VGXLl0UFRWlFStWaNOmTercubMiIiJUt25dSVKzZs0UFhamF154Qdu2bdPixYs1YMAAde/e3aEqSY54bGx8fLxtpeyMChcurBMnTpgQEQAAAO5XFuWOFav/+usvPfvsszp79qwKFy6s+vXra926dbZ5yePHj5eLi4vatWun5ORkNW/eXJMmTbK939XVVQsWLFC3bt0UERGhAgUKKDIyUsOGDXMojhyRUBQvXlyrV69WqVKl7NpXr16tkJAQk6ICAAAAcq6vvvrqtvs9PDz06aef6tNPP71lnxIlSuinn376R3HkiISia9eu6tmzp1JTU22Pj122bJn69u2rXr16mRwdAAAA7ifOrFh9P8sRCUWfPn109uxZvf7667YVsz08PNSvXz/179/f5OgAAAAA3EqOSCgsFos++OADDRw4UHv27JGnp6fKli3r9COzAAAAAGeZubBdbpQjnvJ0Q3x8vM6dO6fSpUvLarXKMAyzQwIAAABwGzkioTh79qwaN26scuXKqWXLlrYnO3Xp0oU5FAAAAEAOliMSirfffltubm6Ki4tT/vz5be3t27fXokWLTIwMAAAA9xuLxbwtN8oRcyiWLFmixYsXq1ixYnbtZcuW1Z9//mlSVAAAAADuJEckFJcuXbKrTNxw7tw5JmYDAAAgW7nk1lKBSXLEkKeHH35YX3zxhe21xWJRenq6Ro8erUaNGpkYGQAAAIDbyREVig8//FCPPvqoNm7cqJSUFPXt21e7du3SuXPntHr1arPDAwAAAHALpicUqampevPNNzV//nwtXbpUBQsWVFJSktq2bavu3burSJEiZocIAACA+wgjnhxjekLh5uam7du3y8/PT++9957Z4QAAAABwQI6YQ/H8889rxowZZocBAAAAyGKxmLblRqZXKCTp2rVr+vzzz/XLL7+oZs2aKlCggN3+cePGmRQZAAAAgNvJEQnFzp07VaNGDUnSH3/8Ybcvt2ZqAAAAyJ348dMxOSKhWLFihdkhAAAAAHBCjphDAQAAACB3yhEVCgAAACCnYKVsx1ChAAAAAOA0KhQAAABABtQnHEOFAgAAAIDTSCgAAAAAOI0hTwAAAEAGrIPmGCoUAAAAAJyWpQrF9u3bs3zAqlWrOh0MAAAAYDYXChQOyVJCUb16dVksFhmGcdP9N/ZZLBalpaXd1QABAAAA5FxZSigOHz58r+MAAAAAcgTmUDgmSwlFiRIl7nUcAAAAAHIhpyZlz549W/Xq1VNISIj+/PNPSdKECRP0448/3tXgAAAAAORsDicUkydPVlRUlFq2bKmEhATbnAlfX19NmDDhbscHAAAAZCuLxbwtN3I4oZg4caKmTZum9957T66urrb2WrVqaceOHXc1OAAAAAA5m8ML2x0+fFjh4eGZ2q1Wqy5dunRXggIAAADMwqRsxzhcoShVqpS2bt2aqX3RokWqWLHi3YgJAAAAQC7hcIUiKipK3bt319WrV2UYhtavX69///vfio6O1vTp0+9FjAAAAAByKIcTipdfflmenp4aMGCALl++rOeee04hISH66KOP1KFDh3sRIwAAAJBtWCnbMQ4nFJLUsWNHdezYUZcvX1ZSUpICAwPvdlwAAAAAcgGnEgpJOnXqlPbt2yfp+sSVwoUL37WgAAAAALMwKdsxDk/Kvnjxol544QWFhISoYcOGatiwoUJCQvT888/rwoUL9yJGAAAAADmUwwnFyy+/rNjYWC1cuFAJCQlKSEjQggULtHHjRr366qv3IkYAAAAg21hM3HIjh4c8LViwQIsXL1b9+vVtbc2bN9e0adP02GOP3dXgAAAAAORsDlcoAgIC5OPjk6ndx8dHfn5+dyUoAAAAALmDwwnFgAEDFBUVpfj4eFtbfHy8+vTpo4EDB97V4AAAAIDs5mKxmLblRlka8hQeHm43233//v0KDQ1VaGioJCkuLk5Wq1WnT59mHgUAAABwH8lSQtGmTZt7HAYAAACQM+TSQoFpspRQDB48+F7HAQAAACAXcngOBQAAAADc4PBjY9PS0jR+/Hh9/fXXiouLU0pKit3+c+fO3bXgAAAAgOzGStmOcbhCMXToUI0bN07t27fXhQsXFBUVpbZt28rFxUVDhgy5ByECAAAAyKkcTijmzJmjadOmqVevXsqXL5+effZZTZ8+XYMGDdK6devuRYwAAABAtrFYzNtyI4cTivj4eFWpUkWS5OXlpQsXLkiSHn/8cS1cuPDuRgcAAAAgR3M4oShWrJhOnDghSSpdurSWLFkiSdqwYYOsVuvdjQ4AAABAjubwpOynnnpKy5YtU506dfTGG2/o+eef14wZMxQXF6e33377XsQIAAAAZJvcumK1WRxOKN5//33bn9u3b68SJUpozZo1Klu2rJ544om7GhwAAACAnO0fr0NRt25dRUVFqU6dOho1atTdiAkAAAAwDZOyHXPXFrY7ceKEBg4ceLcOBwAAACAXcHjIEwAAAJCXsbCdY+5ahQIAAADA/YeEAgAAAIDTsjzkKSoq6rb7T58+/Y+DuVvc85EnIXuMW3nQ7BBwn4hqWNrsEADgvsFPko7JckKxZcuWO/Zp0KDBPwoGAAAAQO6S5YRixYoV9zIOAAAAIEdgUrZjqOgAAAAAcBoJBQAAAACnsQ4FAAAAkIELI54cQoUCAAAAyOXef/99WSwW9ezZ09Z29epVde/eXQEBAfLy8lK7du108uRJu/fFxcWpVatWyp8/vwIDA9WnTx9du3bNoXOTUAAAAAAZuFjM25yxYcMGTZ06VVWrVrVrf/vttzV//nx98803WrlypY4fP662bdva9qelpalVq1ZKSUnRmjVrFBMTo1mzZmnQoEGOfV7OBP3bb7/p+eefV0REhI4dOyZJmj17tn7//XdnDgcAAABAUnJyshITE+225OTkW/ZPSkpSx44dNW3aNPn5+dnaL1y4oBkzZmjcuHF69NFHVbNmTc2cOVNr1qzRunXrJElLlizR7t279eWXX6p69epq0aKFhg8frk8//VQpKSlZjtnhhOK7775T8+bN5enpqS1bttgu8MKFCxo1apSjhwMAAAByFIvFYtoWHR0tHx8fuy06OvqWsXbv3l2tWrVSkyZN7No3bdqk1NRUu/YKFSooNDRUa9eulSStXbtWVapUUVBQkK1P8+bNlZiYqF27dmX583I4oRgxYoSmTJmiadOmyc3NzdZer149bd682dHDAQAAAPh//fv314ULF+y2/v3737TvV199pc2bN9804YiPj5e7u7t8fX3t2oOCghQfH2/rkzGZuLH/xr6scvgpT/v27bvpitg+Pj5KSEhw9HAAAAAA/p/VapXVar1jv6NHj+qtt97S0qVL5eHhkQ2R3ZrDFYrg4GAdOHAgU/vvv/+uBx544K4EBQAAAJglN0zK3rRpk06dOqUaNWooX758ypcvn1auXKmPP/5Y+fLlU1BQkFJSUjL9wv/kyZMKDg6WdP3n+r8/9enG6xt9svR5ZT3s67p27aq33npLsbGxslgsOn78uObMmaPevXurW7dujh4OAAAAgIMaN26sHTt2aOvWrbatVq1a6tixo+3Pbm5uWrZsme09+/btU1xcnCIiIiRJERER2rFjh06dOmXrs3TpUnl7eyssLCzLsTg85Omdd95Renq6GjdurMuXL6tBgwayWq3q3bu33njjDUcPBwAAAOQollywsF3BggVVuXJlu7YCBQooICDA1t6lSxdFRUXJ399f3t7eeuONNxQREaG6detKkpo1a6awsDC98MILGj16tOLj4zVgwAB17949S8OubnA4obBYLHrvvffUp08fHThwQElJSQoLC5OXl5ejhwIAAABwj4wfP14uLi5q166dkpOT1bx5c02aNMm239XVVQsWLFC3bt0UERGhAgUKKDIyUsOGDXPoPBbDMIy7HbzZrjq2uB/gtHErD5odAu4TUQ1Lmx0CANxVHg7/Wjv79F24z7Rzj25V3rRzO8vhv8pGjRrJcps60PLly/9RQAAAAICZXHLDmKccxOGEonr16navU1NTtXXrVu3cuVORkZF3Ky4AAAAAuYDDCcX48eNv2j5kyBAlJSX944AAAAAAMzn8GNT73F37vJ5//nl9/vnnd+twAAAAAHKBuzYdZu3ataav0gcAAAD8U0yhcIzDCUXbtm3tXhuGoRMnTmjjxo0aOHDgXQsMAAAAQM7ncELh4+Nj99rFxUXly5fXsGHD1KxZs7sWGAAAAICcz6GEIi0tTZ07d1aVKlXk5+d3r2ICAAAATMNjYx3j0KRsV1dXNWvWTAkJCfcoHAAAAAC5icNPeapcubIOHTp0L2IBAAAATGexmLflRg4nFCNGjFDv3r21YMECnThxQomJiXYbAAAAgPtHludQDBs2TL169VLLli0lSU8++aQsGdIowzBksViUlpZ296MEAAAAkCNlOaEYOnSoXnvtNa1YseJexgMAAACYyiWXDj0yS5YTCsMwJEkNGza8Z8EAAAAAyF0cemysJbfOFAEAAACyiMfGOsahhKJcuXJ3TCrOnTv3jwICAAAAkHs4lFAMHTo000rZAAAAQF5CgcIxDiUUHTp0UGBg4L2KBQAAAEAuk+V1KJg/AQAAAODvHH7KEwAAAJCX8dhYx2Q5oUhPT7+XcQAAAADIhRyaQwEAAADkdRZRonBEludQAAAAAMDfkVAAAAAAcBpDngAAAIAMmJTtGCoUAAAAAJxGhQIAAADIgAqFY6hQAAAAAHAaFQoAAAAgA4uFEoUjqFAAAAAAcBoJBQAAAACnMeQJAAAAyIBJ2Y6hQgEAAADAaVQoAAAAgAyYk+0YKhQAAAAAnEZCAQAAAMBpDHkCAAAAMnBhzJNDqFAAAAAAcBoVCgAAACADHhvrGCoUAAAAAJxGhQIAAADIgCkUjskRFYrZs2erXr16CgkJ0Z9//ilJmjBhgn788UeTIwMAAABwO6YnFJMnT1ZUVJRatmyphIQEpaWlSZJ8fX01YcIEc4MDAAAAcFumJxQTJ07UtGnT9N5778nV1dXWXqtWLe3YscPEyAAAAHA/cpHFtC03Mj2hOHz4sMLDwzO1W61WXbp0yYSIAAAAAGSV6QlFqVKltHXr1kztixYtUsWKFbM/IAAAANzXLBbzttzI9Kc8RUVFqXv37rp69aoMw9D69ev173//W9HR0Zo+fbrZ4QEAAAC4DdMTipdfflmenp4aMGCALl++rOeee04hISH66KOP1KFDB7PDAwAAAHAbpicUktSxY0d17NhRly9fVlJSkgIDA80OCQAAAPcpVsp2jOlzKK5cuaLLly9LkvLnz68rV65owoQJWrJkicmRAQAAALgT0ysUrVu3Vtu2bfXaa68pISFBDz74oNzd3XXmzBmNGzdO3bp1MztEAAAA3EdccuvsaJOYXqHYvHmzHn74YUnSt99+q+DgYP3555/64osv9PHHH5scHQAAAIDbMT2huHz5sgoWLChJWrJkidq2bSsXFxfVrVtXf/75p8nRAQAAALgd0xOKMmXKaN68eTp69KgWL16sZs2aSZJOnTolb29vk6MDAADA/YZ1KBxj+hyKQYMG6bnnntPbb7+tRx99VBEREZKuVytutoI27r6v5s5RzMwZOnPmtMqVr6B33h2oKlWrmh0WcpG9qxbqj1ULlXTupCTJt0gJVW35rIpVqm3rc+rQHm35b4zOHNkni4uL/Io9oKY9Riifu1WSlHzpomK/nqy/dsRKFheVqF5PD/7rVbl5eJpyTcjd+F5DduFeAySLYRiG2UHEx8frxIkTqlatmlxcrhdN1q9fL29vb1WoUMHh4129drcjzLsW/fyTBvTvqwGDh6pKlWqaMztGS5Ys0o8LFikgIMDs8HK8cSsPmh1CjnB0e6wsLi7yDgyRYRg6uG6Zdv3ynR7vP1F+ISV06tAe/fLJQFVp/oyKVakjF1dXnf/rkIpXjZCrm5sk6ZdPBupy4nlFPNtD6WlpWj17vAqVKKsGL/Uz+epyhqiGpc0OIdfgew3ZhXvtn/Ew/dfatzZjfZxp5+7yYKhp53aW6UOeJCk4OFjh4eE6duyYjh49Kkl68MEHnUom4JjZMTPV9uln1OapdipdpowGDB4qDw8Pzfv+O7NDQy5SvGodFatcW96BReUTVEw1Wkcqn9VDZw7vlSRt+PYzVWz0pKo0f0Z+ISXkE1RMJWs2sCUTCSfidGz3Jj3U8U0VLlVBQWUqqc4zr+nwplW6nHDWzEtDLsT3GrIL9xpwnekJxbVr1zRw4ED5+PioZMmSKlmypHx8fDRgwAClpqaaHV6elpqSoj27d6luxEO2tusT4h/S9m1bTIwMuVl6epoOb1ypaylXVfiBirpyMUFnjuyTh5evfvqwl/7T7zktGtdXJw/ssr3n9OG9cvf0UqES5WxtRSqEy2Kx6PSRfWZcBnIpvteQXbjX8jbmUDjG9GLTG2+8oe+//16jR4+2zZ9Yu3athgwZorNnz2ry5MkmR5h3nU84r7S0tExl2YCAAB0+fMikqJBbnT92WD+N6aW01BTls3qq0SsD5VskVKf/v0qx7ac5qtm2i/yLldbB2GVa8nF/tR4wWd6BRXUl8bw8CvrYHc/F1VXW/AV1JfG8GZeDXIrvNWQX7jXgf0xPKObOnauvvvpKLVq0sLVVrVpVxYsX17PPPnvHhCI5OVnJycl2bYarVVar9Z7EC+DmvIOK6Yn+nyj16iUd2fy7fv9irB57e7SM9HRJUrn6LVQ24vpT3AKKl1b83q3av2aJarbpbGbYAADgHzJ9yJPValXJkiUztZcqVUru7u53fH90dLR8fHzstg8/iL4HkeY9fr5+cnV11dmz9mPUz549q0KFCpkUFXIr13xu8g4MUUBoWdVs01n+RR/QnhU/ytPHX5LkE2w/ycwnuLgunT8tSfL09tPVixfs9qenpSn58kV5evtlzwUgT+B7DdmFey1vczFxy41Mj7tHjx4aPny4XZUhOTlZI0eOVI8ePe74/v79++vChQt2W59+/e9lyHmGm7u7KoZVUuy6tba29PR0xcauVdVqPLIX/4xhpCvtWqq8AoLk6ROgxFN/2e1PPHVMXv6BkqTCpSoo5UqSzsbtt+0/sW+bDMNQ4ZLlszVu5G58ryG7cK8B/2P6kKctW7Zo2bJlKlasmKpVqyZJ2rZtm1JSUtS4cWO1bdvW1vf777/P9H6rNfPwJh4bm3UvRHbWwHf7qVKlyqpcpaq+nB2jK1euqM1Tbe/8ZuD/bZo3U0Ur1ZKXf6BSr17WoQ2/Kn7/DjXtMVwWi0WVm7bT1gVfyq/oA/Iv9oAOxv6iCyf/UsOu70mSfIuEqmhYTa2Z87HqPttDRto1rf96kkrVbKD8vjx6EY7hew3ZhXst77Lk1tnRJjE9ofD19VW7du3s2ooXL25SNPefx1q01Plz5zTpk4915sxpla9QUZOmTlcA5Vo44OrFC/o9ZqyuJJ6Tu0cB+RUtpaY9hiukYg1JUtijbZSWmqIN336mlMsX5Vf0ATV9Y6S8CxexHePhzn0V+59JWvLRu7JYLCoRXk8P/us1sy4JuRjfa8gu3Gsw2+TJkzV58mQdOXJEklSpUiUNGjTINjf56tWr6tWrl7766islJyerefPmmjRpkoKCgmzHiIuLU7du3bRixQp5eXkpMjJS0dHRypcv62lCjljY7m6jQoHswsJ2yC4sbAcgr8nJC9vFbDxq2rkja2X9F+vz58+Xq6urypYtK8MwFBMTow8//FBbtmxRpUqV1K1bNy1cuFCzZs2Sj4+PevToIRcXF61evVqSlJaWpurVqys4OFgffvihTpw4oRdffFFdu3bVqFGjshwHCQXwD5BQILuQUADIa3JyQvGFiQnFiw4kFDfj7++vDz/8UE8//bQKFy6suXPn6umnn5Yk7d27VxUrVtTatWtVt25d/fzzz3r88cd1/PhxW9ViypQp6tevn06fPp2lByRJJg15qlGjhpYtWyY/Pz+Fh4ffdpza5s2bszEyAAAAwDw3WxLhZnOG/y4tLU3ffPONLl26pIiICG3atEmpqalq0qSJrU+FChUUGhpqSyjWrl2rKlWq2A2Bat68ubp166Zdu3YpPDxrDxgwJaFo3bq17UNp06aNGSEAAAAAN+Vi4qTs6OhoDR061K5t8ODBGjJkyE3779ixQxEREbp69aq8vLz0ww8/KCwsTFu3bpW7u7t8fX3t+gcFBSk+Pl6SFB8fb5dM3Nh/Y19WmZJQDB48+KZ/BgAAAO5n/fv3V1RUlF3b7aoT5cuX19atW3XhwgV9++23ioyM1MqVK+91mHZy8Og1AAAAIPuZ+dDYrAxvysjd3V1lypSRJNWsWVMbNmzQRx99pPbt2yslJUUJCQl2VYqTJ08qODhYkhQcHKz169fbHe/kyZO2fVllysJ2fn5+8vf3z9IGAAAAIGvS09OVnJysmjVrys3NTcuWLbPt27dvn+Li4hQRESFJioiI0I4dO3Tq1Clbn6VLl8rb21thYWFZPqcpFYoJEyaYcVoAAAAgz+jfv79atGih0NBQXbx4UXPnztWvv/6qxYsXy8fHR126dFFUVJT8/f3l7e2tN954QxEREapbt64kqVmzZgoLC9MLL7yg0aNHKz4+XgMGDFD37t0dqpKYklBERkaacVoAAADgjnLLQtmnTp3Siy++qBMnTsjHx0dVq1bV4sWL1bRpU0nS+PHj5eLionbt2tktbHeDq6urFixYoG7duikiIkIFChRQZGSkhg0b5lAcpqxDkZiYmOW+3t7eDh+fdSiQXViHAtmFdSgA5DU5eR2KuZv/Mu3cz9UoZtq5nWXKX6Wvr+9t156QJMMwZLFYlJaWlk1RAQAAALrjz6mwZ0pCsWLFCjNOCwAAAOAuMyWhaNiwod3r3377TVOnTtXBgwf17bffqmjRopo9e7ZKlSplRngAAAAAssiUx8Zm9N1336l58+by9PTUli1bbEuNX7hwQaNGjTI5OgAAANxvXEzcciPT4x4xYoSmTJmiadOmyc3NzdZer149bd682cTIAAAAANyJ6fPr9+3bpwYNGmRq9/HxUUJCQvYHBAAAgPsak7IdY3qFIjg4WAcOHMjU/vvvv+uBBx4wISIAAAAAWWV6QtG1a1e99dZbio2NlcVi0fHjxzVnzhz17t1b3bp1Mzs8AAAA3GcsJm65kelDnt555x2lp6ercePGunz5sho0aCCr1arevXvrjTfeMDs8AAAAALdhekJhsVj03nvvqU+fPjpw4ICSkpIUFhYmLy8vs0MDAAAAcAemJxQ3uLu7KywszOwwAAAAcJ9jUrZjTJ9DAQAAACD3yjEVCgAAACAn4DfujuHzAgAAAOA0EgoAAAAATmPIEwAAAJABk7IdQ4UCAAAAgNOoUAAAAAAZUJ9wDBUKAAAAAE6jQgEAAABkwBQKx1ChAAAAAOA0EgoAAAAATmPIEwAAAJCBC9OyHUKFAgAAAIDTqFAAAAAAGTAp2zFUKAAAAAA4jYQCAAAAgNMY8gQAAABkYGFStkOoUAAAAABwGhUKAAAAIAMmZTuGCgUAAAAAp1GhAAAAADJgYTvHUKEAAAAA4DQSCgAAAABOY8gTAAAAkAGTsh1DhQIAAACA06hQAAAAABlQoXAMFQoAAAAATiOhAAAAAOA0hjwBAAAAGVhYh8IhVCgAAAAAOI0KBQAAAJCBCwUKh1ChAAAAAOA0KhQAAABABsyhcAwVCgAAAABOI6EAAAAA4DSGPAEAAAAZsFK2Y6hQAAAAAHAaFQoAAAAgAyZlO4YKBQAAAACnkVAAAAAAcBpDngAAAIAMWCnbMVQoAAAAADiNCgUAAACQAZOyHUOFAgAAAIDTSCgAAAAAOI0hTwAAAEAGrJTtGCoUAAAAAJxGhQIAAADIgAKFY6hQAAAAAHAaFQoAAAAgAxcmUTiECgUAAAAAp5FQAAAAAHBanhzy5Fe7h9kh4D5xJnai2SEAAIC7jAFPjqFCAQAAAORC0dHRql27tgoWLKjAwEC1adNG+/bts+tz9epVde/eXQEBAfLy8lK7du108uRJuz5xcXFq1aqV8ufPr8DAQPXp00fXrl3LchwkFAAAAEBGFhM3B6xcuVLdu3fXunXrtHTpUqWmpqpZs2a6dOmSrc/bb7+t+fPn65tvvtHKlSt1/PhxtW3b1rY/LS1NrVq1UkpKitasWaOYmBjNmjVLgwYNyvrHZRiG4VjoOZ9nOEOekD0Y8oTs4upCAR5A3uKRgwferzuYYNq565b2dfq9p0+fVmBgoFauXKkGDRrowoULKly4sObOnaunn35akrR3715VrFhRa9euVd26dfXzzz/r8ccf1/HjxxUUFCRJmjJlivr166fTp0/L3d39juelQgEAAADkEMnJyUpMTLTbkpOTs/TeCxcuSJL8/f0lSZs2bVJqaqqaNGli61OhQgWFhoZq7dq1kqS1a9eqSpUqtmRCkpo3b67ExETt2rUrS+cloQAAAAAysJj4X3R0tHx8fOy26OjoO8acnp6unj17ql69eqpcubIkKT4+Xu7u7vL19bXrGxQUpPj4eFufjMnEjf039mVFDi42AQAAAPeX/v37Kyoqyq7NarXe8X3du3fXzp079fvvv9+r0G6JhAIAAADIwMyFsq1Wa5YSiIx69OihBQsWaNWqVSpWrJitPTg4WCkpKUpISLCrUpw8eVLBwcG2PuvXr7c73o2nQN3ocycMeQIAAAByIcMw1KNHD/3www9avny5SpUqZbe/Zs2acnNz07Jly2xt+/btU1xcnCIiIiRJERER2rFjh06dOmXrs3TpUnl7eyssLCxLcVChAAAAADLILc/V6969u+bOnasff/xRBQsWtM158PHxkaenp3x8fNSlSxdFRUXJ399f3t7eeuONNxQREaG6detKkpo1a6awsDC98MILGj16tOLj4zVgwAB17949y5USEgoAAAAgF5o8ebIk6ZFHHrFrnzlzpjp16iRJGj9+vFxcXNSuXTslJyerefPmmjRpkq2vq6urFixYoG7duikiIkIFChRQZGSkhg0bluU4WIcC+AdYhwLZhXUoAOQ1OXkdig2HLph27toP+Jh2bmfl4L9KAAAAwAT8DschTMoGAAAA4DQqFAAAAEAGFkoUDqFCAQAAAMBpJBQAAAAAnMaQJwAAACADM1fKzo2oUAAAAABwGhUKAAAAIAMKFI6hQgEAAADAaVQoAAAAgIwoUTiECgUAAAAAp5FQAAAAAHAaQ54AAACADFgp2zFUKAAAAAA4jQoFAAAAkAEL2zmGCgUAAAAAp5FQAAAAAHAaQ54AAACADBjx5BgqFAAAAACcRoUCAAAAyIgShUOoUAAAAABwGhUKAAAAIAMWtnMMFQoAAAAATiOhAAAAAOA0hjwBAAAAGbBStmOoUAAAAABwGhUKAAAAIAMKFI6hQgEAAADAaSQUAAAAAJzGkCcAAAAgI8Y8OYQKBQAAAACnUaEAAAAAMmClbMdQoQAAAADgNCoUAAAAQAYsbOcYKhQAAAAAnEZCAQAAAMBpDHkCAAAAMmDEk2OoUAAAAABwGhUKAAAAICNKFA6hQgEAAADAaSQUAAAAAJzGkCcAAAAgA1bKdgwVCgAAAABOo0IBAAAAZMBK2Y6hQgEAAADAaVQoAAAAgAwoUDiGCgUAAAAAp5FQAAAAAHAaQ54AAACAjBjz5BBTKxSpqanKly+fdu7caWYYAAAAAJxkaoXCzc1NoaGhSktLMzMMAAAAwIaF7Rxj+hyK9957T++++67OnTtndigAAAAAHGT6HIpPPvlEBw4cUEhIiEqUKKECBQrY7d+8ebNJkQEAAAC4E9MTijZt2pgdAgAAAGDDStmOMT2hGDx4sNkhAAAAAHCS6XMoJCkhIUHTp09X//79bXMpNm/erGPHjpkcGQAAAO43FhO33Mj0CsX27dvVpEkT+fj46MiRI+ratav8/f31/fffKy4uTl988YXZIQIAAAC4BdMrFFFRUerUqZP2798vDw8PW3vLli21atUqEyMDAAAAcCemVyg2bNigqVOnZmovWrSo4uPjTYgIAAAA97XcOvbIJKYnFFarVYmJiZna//jjDxUuXNiEiPIOFxeLBrzWUs+2rK2gAG+dOH1Bs+fH6v1piyRJ+fK5aMjrT6h5/UoqVSxAiUlXtTx2rwZ+/F+dOH3B7liP1a+kd19pocplQ3Q15Zp+37Rfz0RNM+OykEts2rhBX8yaoT27d+nM6dMaO+ETNWrcxLZ/8HvvaP5/59m9J6JefX06ZXo2R4q86Ku5cxQzc4bOnDmtcuUr6J13B6pK1apmh4U8iHsNyAEJxZNPPqlhw4bp66+/liRZLBbFxcWpX79+ateuncnR5W69OjVV16cfVtdBs7X74AnVrBSqqUOeV2LSFU3690rl93BX9YrF9f60n7X9j2Py886vMX2e1jcTXlX9jqNtx2nTuLo+HfisBn8yX7+u/0P58rmoUukiJl4ZcoOrV66oXLkKav1UO/Xu+cZN+zxU72ENGTHK9trdzT27wkMetujnnzRmdLQGDB6qKlWqac7sGHV7tYt+XLBIAQEBZoeHPIR7Le9ipWzHmJ5QjB07Vk8//bQCAwN15coVNWzYUPHx8YqIiNDIkSPNDi9Xq1vtAS1YuV2Lft8lSYo7cU7PPFZLtSqVkCQlJl3V490+sXvP2+9/rd/n9FXxYD8djT8vV1cXjenTTu9OmKeYeWtt/fYeYjgabq/eww1U7+EGt+3j7u6uQoWoROLumh0zU22ffkZtnrr+S6kBg4dq1apfNe/779Sl6ysmR4e8hHsNuM70hMLHx0dLly7V77//ru3btyspKUk1atRQkyZN7vxm3Na6bYfUpV09lQkN1IG4U6pSrqgiqj+gd8Z+f8v3eBf0VHp6uhIuXpEkhVcorqJBfkpPN7T23/0UFOCt7X/8pXfHz9Pugyey61KQR23cuF6NGz4kb29v1X6wrl5/4y35+vqZHRZysdSUFO3ZvUtdur5qa3NxcVHdug9p+7YtJkaGvIZ7LW9jYTvHmP6Upxvq16+v119/XX379iWZuEvGzFyqbxZv0rYfBihx/Uda9+9++mTur/rq54037W91z6cRb7bW14s26eKlq5KkUsUKSZIGvNZSH0xfrHZvTVFC4hUtnvaW/LzzZ9u1IO95qP7DGj7yA02ZNlNv9uytTRs36I1urygtLc3s0JCLnU84r7S0tEzDTQICAnTmzBmTokJexL2GnGDVqlV64oknFBISIovFonnz5tntNwxDgwYNUpEiReTp6akmTZpo//79dn3OnTunjh07ytvbW76+vurSpYuSkpIcisP0CoUkLVu2TMuWLdOpU6eUnp5ut+/zzz+/7XuTk5OVnJxs12akp8ni4nrX48xtnm5WQx1a1Fand2O0++AJVS1fVB/2flonTl/QnPmxdn3z5XPRl6O7yGKx6M1R/7G1u/x/iv7B9MWat2yrJOmVwV/qwOLhats0XDO+W51t14O8pXmLVrY/ly1XXmXLldeTLZtq44b1qlM3wsTIAADIHS5duqRq1arppZdeUtu2bTPtHz16tD7++GPFxMSoVKlSGjhwoJo3b67du3fblmvo2LGjTpw4oaVLlyo1NVWdO3fWK6+8orlz52Y5DtMTiqFDh2rYsGGqVauWihQpIouDNabo6GgNHTrUrs01qLbcijx4N8PMlUb1bGOrUkjSrgPHFVrEX306N7VLKPLlc9GcD7ootIifWrwy0VadkKQTZ64/7Wnvof8Nb0pJvaYjf51V8WD/bLoS3A+KFS8uXz8/HY37k4QCTvPz9ZOrq6vOnj1r13727FkVKlTIpKiQF3Gv5W25ZcRTixYt1KJFi5vuMwxDEyZM0IABA9S6dWtJ0hdffKGgoCDNmzdPHTp00J49e7Ro0SJt2LBBtWrVkiRNnDhRLVu21JgxYxQSEpKlOEwf8jRlyhTNmjVLsbGxmjdvnn744Qe77U769++vCxcu2G35gmpmQ+Q5n6eHu9IN+4pPWrohF5f//bXfSCZKhxZWq9c+0bkLl+z6b9lzVFeTU1W2ZJDde0JD/BV34ty9vQDcV07Gx+tCQoIKFw40OxTkYm7u7qoYVkmx6/73EIn09HTFxq5V1WrhJkaGvIZ7DfdKcnKyEhMT7ba/j8bJisOHDys+Pt5uKoGPj4/q1KmjtWuv37dr166Vr6+vLZmQpCZNmsjFxUWxsbGZjnkrplcoUlJS9NBDDzn9fqvVKqvVatfGcKfrflq1Q/26NNfRE+e1++AJVa9QTG8+30hfzFsn6XpiMPfDlxVeobjavjVFri4WBQUUlCSdu3BZqdfSdPHSVU3/9ncNfK2l/oo/r7gT5/R25PUb8/ulm027NuR8ly9f0tG4ONvrY8f+0r69e+Tt4yMfHx9NnfypGjdppkKFCuno0aP6aNyHKh4aqoh69U2MGnnBC5GdNfDdfqpUqbIqV6mqL2fH6MqVK2rzVObhAMA/wb2Wh5lYorjZ6JvBgwdryJAhDh3nxgLRQUFBdu1BQUG2ffHx8QoMtP9FXr58+eTv7+/QAtOmJxQvv/yy5s6dq4EDB5odSp4T9cE3Gvz64/ro3fYq7OelE6cvaMa3qzXqs58lSSGFffXEI9cX31n/n/5272328kf6bdP1STv9J/yga2npmjHiRXla3bRh559q8crHtidBATeze9dOvfJSpO31uA/flyQ98WQb9R84RPv/2KcF/52ni4kXVTiwsOpG1NPrPd6SuztrUeCfeaxFS50/d06TPvlYZ86cVvkKFTVp6nQFMAwFdxn3Gu6F/v37Kyoqyq7t7788z2kshmEY2X3SjB9Senq6YmJiVLVqVVWtWlVubm52fceNG+fw8T3De/zjGIGsOBM70ewQcJ9wdcktI3oBIGs8TP+19q0dOXv1zp3ukZIBHk69z2Kx6IcfflCbNm0kSYcOHVLp0qW1ZcsWVa9e3davYcOGql69uj766CN9/vnn6tWrl86fP2/bf+3aNXl4eOibb77RU089laVzm/JXuWWL/fOZb1zkzp07TYgGAAAA+J+8sFJ2qVKlFBwcrGXLltl+1k5MTFRsbKy6desmSYqIiFBCQoI2bdqkmjWvz0Fevny50tPTVadOnSyfy5SEYsWKFWacFgAAAMgzkpKSdODAAdvrw4cPa+vWrfL391doaKh69uypESNGqGzZsrbHxoaEhNiqGBUrVtRjjz2mrl27asqUKUpNTVWPHj3UoUOHLD/hScoBT3l66aWXdPHixUztly5d0ksvvWRCRAAAALifWSzmbY7YuHGjwsPDFR5+/cliUVFRCg8P16BBgyRJffv21RtvvKFXXnlFtWvXVlJSkhYtWmRbg0KS5syZowoVKqhx48Zq2bKl6tevr88++8yxz8uMORQZubq66sSJE5lmmJ85c0bBwcG6du2aw8dkDgWyC3MokF2YQwEgr8nJcyjizjn+mNa7JdQ/Z0/AvhnT/ioTExNlGIYMw9DFixftMqW0tDT99NNPmZIMAAAA4F7jVziOMS2h8PX1lcVikcViUbly5TLtt1gsmZ7BCwAAACBnMS2hWLFihQzD0KOPPqrvvvtO/v7+tn3u7u4qUaKEQ5NBAAAAAGQ/0xKKhg0bSro+G93b21uff/659uzZI0mqVKmSwsLCzAoNAAAA9zFHJ0ff70x/ytPp06dVtmxZjR8/XufOndO5c+c0btw4lS5dWps3bzY7PAAAAAC3YfpTnh5++GGVKVNG06ZNU7581wsm165d08svv6xDhw5p1apVDh+Tpzwhu/CUJ2QXnvIEIK/JyU95+ut8imnnLubnbtq5nWX6X+XGjRvtkglJypcvn/r27atatWqZGBkAAACAOzF9yJO3t7fi4uIytR89elQFCxY0ISIAAAAAWWV6haJ9+/bq0qWLxowZo4ceekiStHr1avXp00fPPvusydEBAADgfsOkbMeYnlCMGTNGFotFL774om1VbDc3N3Xr1k3vv/++ydEBAAAAuB3TJ2XfcPnyZR08eFCSVLp0aeXPn9/pYzEpG9mFSdnILkzKBpDX5ORJ2ccTzJuUHeLLpGyn5c+fX1WqVDE7DAAAAAAOyDEJBQAAAJATMIfCMaY/5QkAAABA7kVCAQAAAMBpDHkCAAAAMrCIMU+OoEIBAAAAwGlUKAAAAICMKFA4hAoFAAAAAKeRUAAAAABwGkOeAAAAgAwY8eQYKhQAAAAAnEaFAgAAAMiAlbIdQ4UCAAAAgNOoUAAAAAAZsLCdY6hQAAAAAHAaCQUAAAAApzHkCQAAAMiIEU8OoUIBAAAAwGlUKAAAAIAMKFA4hgoFAAAAAKeRUAAAAABwGkOeAAAAgAxYKdsxVCgAAAAAOI0KBQAAAJABK2U7hgoFAAAAAKdRoQAAAAAyYA6FY6hQAAAAAHAaCQUAAAAAp5FQAAAAAHAaCQUAAAAApzEpGwAAAMiASdmOoUIBAAAAwGkkFAAAAACcxpAnAAAAIANWynYMFQoAAAAATqNCAQAAAGTApGzHUKEAAAAA4DQqFAAAAEAGFCgcQ4UCAAAAgNNIKAAAAAA4jSFPAAAAQEaMeXIIFQoAAAAATqNCAQAAAGTAwnaOoUIBAAAAwGkkFAAAAACcxpAnAAAAIANWynYMFQoAAAAATqNCAQAAAGRAgcIxVCgAAAAAOI2EAgAAAIDTGPIEAAAAZMSYJ4dQoQAAAADgNCoUAAAAQAaslO0YKhQAAABALvXpp5+qZMmS8vDwUJ06dbR+/fpsj4GEAgAAAMjAYjFvc8R//vMfRUVFafDgwdq8ebOqVaum5s2b69SpU/fmg7kFEgoAAAAgFxo3bpy6du2qzp07KywsTFOmTFH+/Pn1+eefZ2scJBQAAABADpGcnKzExES7LTk5OVO/lJQUbdq0SU2aNLG1ubi4qEmTJlq7dm12hpw3J2Vf2fKJ2SHkOsnJyYqOjlb//v1ltVrNDgd5GPcasgv3GrIL91re42HiT8hDRkRr6NChdm2DBw/WkCFD7NrOnDmjtLQ0BQUF2bUHBQVp79699zpMOxbDMIxsPSNypMTERPn4+OjChQvy9vY2OxzkYdxryC7ca8gu3Gu4m5KTkzNVJKxWa6Zk9fjx4ypatKjWrFmjiIgIW3vfvn21cuVKxcbGZku8Uh6tUAAAAAC50c2Sh5spVKiQXF1ddfLkSbv2kydPKjg4+F6Fd1PMoQAAAAByGXd3d9WsWVPLli2ztaWnp2vZsmV2FYvsQIUCAAAAyIWioqIUGRmpWrVq6cEHH9SECRN06dIlde7cOVvjIKGApOvltcGDBzOZDPcc9xqyC/casgv3GszSvn17nT59WoMGDVJ8fLyqV6+uRYsWZZqofa8xKRsAAACA05hDAQAAAMBpJBQAAAAAnEZCAQAAAMBpJBT3sUceeUQ9e/Y0OwzkYr/++qssFosSEhIkSbNmzZKvr69t/5AhQ1S9enVTYgPuhb/f48g7zPq+4p5CXkBCcR/4+w99QHbp3bu33fOxgX/qyJEjslgs2rp1q9mhIJfI6i/P+L4CnMdjY3FXpaSkyN3d3ewwkEN4eXnJy8vL7DCQg/AdgZzGMAylpaXxfQX8A1Qo8ojk5GS9+eabCgwMlIeHh+rXr68NGzboyJEjatSokSTJz89PFotFnTp1sr0vPT1dffv2lb+/v4KDgzVkyBC74yYkJOjll19W4cKF5e3trUcffVTbtm2z7b9RIp4+fbpKlSolDw+P7LhcZKP09HRFR0erVKlS8vT0VLVq1fTtt99m6b1/H0LQqVMntWnTRkOHDrXdU6+99ppSUlJsfb799ltVqVJFnp6eCggIUJMmTXTp0iXb/unTp6tixYry8PBQhQoVNGnSpLt2rbj7HnnkEfXo0UM9e/ZUoUKF1Lx5c+3cuVMtWrSQl5eXgoKC9MILL+jMmTO296Snp2v06NEqU6aMrFarQkNDNXLkSElSqVKlJEnh4eGyWCx65JFHJEkbNmxQ06ZNVahQIfn4+Khhw4bavHmzXSwWi0XTp0/XU089pfz586ts2bL673//a9fnv//9r8qWLSsPDw81atRIMTExd6zw/vjjj6pRo4Y8PDz0wAMPaOjQobp27dpd+PTwT3Xq1EkrV67URx99JIvFIovFolmzZslisejnn39WzZo1ZbVa9fvvv2f6vuKeAhxgIE948803jZCQEOOnn34ydu3aZURGRhp+fn7GmTNnjO+++86QZOzbt884ceKEkZCQYBiGYTRs2NDw9vY2hgwZYvzxxx9GTEyMYbFYjCVLltiO26RJE+OJJ54wNmzYYPzxxx9Gr169jICAAOPs2bOGYRjG4MGDjQIFChiPPfaYsXnzZmPbtm2mXD/unREjRhgVKlQwFi1aZBw8eNCYOXOmYbVajV9//dVYsWKFIck4f/68YRiGMXPmTMPHx8f23sGDBxvVqlWzvY6MjDS8vLyM9u3bGzt37jQWLFhgFC5c2Hj33XcNwzCM48ePG/ny5TPGjRtnHD582Ni+fbvx6aefGhcvXjQMwzC+/PJLo0iRIsZ3331nHDp0yPjuu+8Mf39/Y9asWdn1ccBBDRs2NLy8vIw+ffoYe/fuNdatW2cULlzY6N+/v7Fnzx5j8+bNRtOmTY1GjRrZ3tO3b1/Dz8/PmDVrlnHgwAHjt99+M6ZNm2YYhmGsX7/ekGT88ssvxokTJ2zfRcuWLTNmz55t7Nmzx9i9e7fRpUsXIygoyEhMTLQdV5JRrFgxY+7cucb+/fuNN9980/Dy8rId49ChQ4abm5vRu3dvY+/evca///1vo2jRore9x1etWmV4e3sbs2bNMg4ePGgsWbLEKFmypDFkyJB7/MkiKxISEoyIiAija9euxokTJ4wTJ04Yv/zyiyHJqFq1qrFkyRLjwIEDxtmzZzN9X3FPAVlHQpEHJCUlGW5ubsacOXNsbSkpKUZISIgxevToTD/03dCwYUOjfv36dm21a9c2+vXrZxiGYfz222+Gt7e3cfXqVbs+pUuXNqZOnWoYxvUfGN3c3IxTp07dgyuD2a5evWrkz5/fWLNmjV17ly5djGeffdaphMLf39+4dOmSrW3y5MmGl5eXkZaWZmzatMmQZBw5cuSm8ZQuXdqYO3euXdvw4cONiIiIf3ahuGcaNmxohIeH214PHz7caNasmV2fo0eP2n7pkZiYaFitVlsC8XeHDx82JBlbtmy57XnT0tKMggULGvPnz7e1STIGDBhge52UlGRIMn7++WfDMAyjX79+RuXKle2O89577932Hm/cuLExatQou/fMnj3bKFKkyG3jQ/Zp2LCh8dZbb9le3/jemjdvnl2/v39f/R33FHBrzKHIAw4ePKjU1FTVq1fP1ubm5qYHH3xQe/bsUe3atW/53qpVq9q9LlKkiE6dOiVJ2rZtm5KSkhQQEGDX58qVKzp48KDtdYkSJVS4cOG7cSnIYQ4cOKDLly+radOmdu0pKSkKDw936pjVqlVT/vz5ba8jIiKUlJSko0ePqlq1amrcuLGqVKmi5s2bq1mzZnr66afl5+enS5cu6eDBg+rSpYu6du1qe/+1a9fk4+Pj3AUiW9SsWdP2523btmnFihU3Hat+8OBBJSQkKDk5WY0bN3boHCdPntSAAQP066+/6tSpU0pLS9Ply5cVFxdn1y/jd16BAgXk7e1t+87bt29fpu/LBx988Lbn3bZtm1avXm0bkiVJaWlpunr1qi5fvmx3ryNnqVWr1m33c08BWUdCcZ9zc3Oze22xWJSeni5JSkpKUpEiRfTrr79mel/GR9wVKFDgXoYIEyUlJUmSFi5cqKJFi9rts1qtdonl3eDq6qqlS5dqzZo1WrJkiSZOnKj33ntPsbGxtn9Ep02bpjp16mR6H3KujN8RSUlJeuKJJ/TBBx9k6lekSBEdOnTIqXNERkbq7Nmz+uijj1SiRAlZrVZFRETYzc+Rbv+d54ykpCQNHTpUbdu2zbSPOWU5253+7eKeArKOhCIPKF26tNzd3bV69WqVKFFCkpSamqoNGzaoZ8+etieqpKWlOXTcGjVqKD4+Xvny5VPJkiXvdtjIBcLCwmS1WhUXF6eGDRtm2u9MQrFt2zZduXJFnp6ekqR169bJy8tLxYsXl3T9H+N69eqpXr16GjRokEqUKKEffvhBUVFRCgkJ0aFDh9SxY8d/dmEwTY0aNfTdd9+pZMmSypcv8z9BZcuWlaenp5YtW6aXX3450/5bfZ+tXr1akyZNUsuWLSVJR48etZvonRXly5fXTz/9ZNe2YcOGO17Pvn37VKZMGYfOhezj7u7u8L9/EvcU4AgSijygQIEC6tatm/r06SN/f3+FhoZq9OjRunz5srp06aLLly/LYrFowYIFatmypTw9PbP0aLwmTZooIiJCbdq00ejRo1WuXDkdP35cCxcu1FNPPXXHcjFyv4IFC6p37956++23lZ6ervr16+vChQtavXq1vL29bQmsI1JSUtSlSxcNGDBAR44c0eDBg9WjRw+5uLgoNjZWy5YtU7NmzRQYGKjY2FidPn1aFStWlCQNHTpUb775pnx8fPTYY48pOTlZGzdu1Pnz5xUVFXW3Lx/3QPfu3TVt2jQ9++yztifMHThwQF999ZWmT58uDw8P9evXT3379pW7u7vq1aun06dPa9euXerSpYsCAwPl6empRYsWqVixYvLw8JCPj4/Kli2r2bNnq1atWkpMTFSfPn1sSWtWvfrqqxo3bpz69eunLl26aOvWrZo1a5ak64nuzQwaNEiPP/64QkND9fTTT8vFxUXbtm3Tzp07NWLEiH/6ceEuKFmypGJjY3XkyBF5eXlluXrAPQVkHY+NzSPef/99tWvXTi+88IJq1KihAwcOaPHixfLz81PRokU1dOhQvfPOOwoKClKPHj2ydEyLxaKffvpJDRo0UOfOnVWuXDl16NBBf/75p4KCgu7xFSGnGD58uAYOHKjo6GhVrFhRjz32mBYuXGh7fKejGjdurLJly6pBgwZq3769nnzySdvjir29vbVq1Sq1bNlS5cqV04ABAzR27Fi1aNFCkvTyyy9r+vTpmjlzpqpUqaKGDRtq1qxZTseC7BcSEqLVq1crLS1NzZo1U5UqVdSzZ0/5+vrKxeX6P0kDBw5Ur169NGjQIFWsWFHt27e3jUnPly+fPv74Y02dOlUhISFq3bq1JGnGjBk6f/68atSooRdeeMH2GG1HlCpVSt9++62+//57Va1aVZMnT9Z7770n6foQv5tp3ry5FixYoCVLlqh27dqqW7euxo8f71SyjXujd+/ecnV1VVhYmAoXLpxpDsStcE8BWWcxDMMwOwgA94dOnTopISFB8+bNMzsUIEtGjhypKVOm6OjRo2aHgjyCewp5EUOeAAD4f5MmTVLt2rUVEBCg1atX68MPP8xyVRe4Ge4p3A9IKAAA+H/79+/XiBEjdO7cOYWGhqpXr17q37+/2WEhF+Oewv2AIU8AAAAAnMakbAAAAABOI6EAAAAA4DQSCgAAAABOI6EAAAAA4DQSCgAAAABOI6EAgH+oU6dOatOmje31I488op49e2Z7HL/++qssFosSEhLu2Tn+fq3OyI44AQDZh4QCQJ7UqVMnWSwWWSwWubu7q0yZMho2bJiuXbt2z8/9/fffa/jw4Vnqm90/XJcsWVITJkzIlnMBAO4PLGwHIM967LHHNHPmTCUnJ+unn35S9+7d5ebmdtNFpVJSUuTu7n5Xzuvv739XjgMAQG5AhQJAnmW1WhUcHKwSJUqoW7duatKkif773/9K+t/QnZEjRyokJETly5eXJB09elTPPPOMfH195e/vr9atW+vIkSO2Y6alpSkqKkq+vr4KCAhQ37599ff1Qf8+5Ck5OVn9+vVT8eLFZbVaVaZMGc2YMUNHjhxRo0aNJEl+fn6yWCzq1KmTJCk9PV3R0dEqVaqUPD09Va1aNX377bd25/npp59Urlw5eXp6qlGjRnZxOiMtLU1dunSxnbN8+fL66KOPbtp36NChKly4sLy9vfXaa68pJSXFti8rsQMA8g4qFADuG56enjp79qzt9bJly+Tt7a2lS5dKklJTU9W8eXNFRETot99+U758+TRixAg99thj2r59u9zd3TV27FjNmjVLn3/+uSpWrKixY8fqhx9+0KOPPnrL87744otau3atPv74Y1WrVk2HDx/WmTNnVLx4cX333Xdq166d9u3bJ29vb3l6ekqSoqOj9eWXX2rKlCkqW7asVq1apeeff16FCxdWw4YNdfToUbVt21bdu3fXK6+8oo0bN6pXr17/6PNJT09XsWLF9M033yggIEBr1qzRK6+8oiJFiuiZZ56x+9w8PDz066+/6siRI+rcubMCAgI0cuTILMUOAMhjDADIgyIjI43WrVsbhmEY6enpxtKlSw2r1Wr07t3btj8oKMhITk62vWf27NlG+fLljfT0dFtbcnKy4enpaSxevNgwDMMoUqSIMXr0aNv+1NRUo1ixYrZzGYZhNGzY0HjrrbcMwzCMffv2GZKMpUuX3jTOFStWGJKM8+fP29quXr1q5M+f31izZo1d3y5duhjPPvusYRiG0b9/fyMsLMxuf79+/TId6+9KlChhjB8//pb7/6579+5Gu3btbK8jIyMNf39/49KlS7a2yZMnG15eXkZaWlqWYr/ZNQMAci8qFADyrAULFsjLy0upqalKT0/Xc889pyFDhtj2V6lSxW7exLZt23TgwAEVLFjQ7jhXr17VwYMHdeHCBZ04cUJ16tSx7cuXL59q1aqVadjTDVu3bpWrq6tDv5k/cOCALl++rKZNm9q1p6SkKDw8XJK0Z88euzgkKSIiIsvnuJVPP/1Un3/+ueLi4nTlyhWlpKSoevXqdn2qVaum/Pnz2503KSlJR48eVVJS0h1jBwDkLSQUAPKsRo0aafLkyXJ3d1dISIjy5bP/yitQoIDd66SkJNWsWVNz5szJdKzChQs7FcONIUyOSEpKkiQtXLhQRYsWtdtntVqdiiMrvvrqK/Xu3Vtjx45VRESEChYsqA8//FCxsbFZPoZZsQMAzENCASDPKlCggMqUKZPl/jVq1NB//vMfBQYGytvb+6Z9ihQpotjYWDVo0ECSdO3aNW3atEk1atS4af8qVaooPT1dK1euVJMmTTLtv1EhSUtLs7WFhYXJarUqLi7ulpWNihUr2iaY37Bu3bo7X+RtrF69Wg899JBef/11W9vBgwcz9du2bZuuXLliS5bWrVsnLy8vFS9eXP7+/neMHQCQt/CUJwD4fx07dlShQoXUunVr/fbbbzp8+LB+/fVXvfnmm/rrr78kSW+99Zbef/99zZs3T3v37tXrr79+2zUkSpYsqcjISL300kuaN2+e7Zhff/21JKlEiRKyWCxasGCBTp8+raSkJBUsWFC9e/fW22+/rZiYGB08eFCbN2/WxIkTFRMTI0l67bXXtH//fvXp00f79u3T3LlzNWvWrCxd57Fjx7R161a77fz58ypbtqw2btyoxYsX648//tDAgQO1YcOGTO9PSUlRly5dtHv3bv30008aPHiwevToIRcXlyzFDgDIW0goAOD/5c+fX6tWrVJoaKjatm2rihUrqkuXLrp69aqtYtGrVy+98MILioyMtA0Leuqpp2573MmTJ+vpp5/W66+/rgoVKqhr1666dOmSJKlo0aIaOnSo3nnnHQUFBalHjx6SpOHDh2vgwIGKjo5WxYoV9dhjj2nhwoUqVaqUJCk0NFTfffed5s2bp2rVqmnKlCkaNWpUlq5zzJgxCg8Pt9sWLlyoV199VW3btlX79u1Vp04dnT171q5acUPjxo1VtmxZNWjQQO3bt9eTTz5pNzflTrEDAPIWi3GrmYQAAAAAcAdUKAAAAAA4jYQCAAAAgNNIKAAAAAA4jYQCAAAAgNNIKAAAAAA4jYQCAAAAgNNIKAAAAAA4jYQCAAAAgNNIKAAAAAA4jYQCAAAAgNNIKAAAAAA47f8As4pkSJAJW1wAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 1000x800 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "visualize_tests(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0739313e-122e-4d47-a5c0-db5be9fa2411",
   "metadata": {},
   "source": [
    "## IV. Conclusion\n",
    "\n",
    "Ce document démontre l'efficacité des réseaux de neurones convolutifs (CNN) pour catégoriser des formes dessinées à la main, soulignant leur aptitude à interpréter des données visuelles complexes. À partir d'une base théorique solide sur les CNN, nous avons préparé un dataset structuré en ensembles de train, validation, et test, et effectué un prétraitement et une normalisation des images pour maximiser l'apprentissage.\n",
    "\n",
    "En conclusion, le modèle fonctionne bien et remplit sa fonction de classification de forme pour notre whiteboard intelligent."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b94273-3ea4-42cd-8596-71ec8984bdea",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## V. Quelques sources scientifiques utilisées\n",
    "\n",
    "1. **Conv2D avec padding 'same'**:\n",
    "   - **Justification**: Les couches Conv2D permettent d'extraire des caractéristiques locales de l'image d'entrée. Le padding 'same' est utilisé pour conserver les dimensions spatiales de l'image à travers les couches convolutives.\n",
    "   - **Référence**: Simonyan, K., & Zisserman, A. (2014). Very Deep Convolutional Networks for Large-Scale Image Recognition. arXiv:1409.1556. Ce papier introduit VGG, une architecture profonde qui utilise des convolutions avec padding 'same' pour préserver les dimensions.\n",
    "\n",
    "2. **BatchNormalization**:\n",
    "   - **Justification**: La normalisation par lots accélère la formation en réduisant le problème du décalage de la distribution des entrées des couches au cours de l'entraînement. Cette couche est entraînable pour ajuster la normalisation et la rendre la plus bénéfique possible au modèle.\n",
    "   - **Référence**: Ioffe, S., & Szegedy, C. (2015). Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift. arXiv:1502.03167. Ce papier présente BatchNormalization et explique comment elle améliore l'entraînement des réseaux profonds.\n",
    "\n",
    "3. **Activation Mish**:\n",
    "   - **Justification**: Mish est une fonction d'activation non linéaire qui peut améliorer la capacité du modèle à apprendre des fonctions complexes.\n",
    "   - **Référence**: Misra, D. (2019). Mish: A Self Regularized Non-Monotonic Neural Activation Function. arXiv:1908.08681. Cette étude introduit Mish et démontre ses avantages par rapport à d'autres fonctions d'activation comme ReLU.\n",
    "\n",
    "4. **MaxPooling2D**:\n",
    "   - **Justification**: Le pooling maximal réduit les dimensions spatiales de l'entrée, ce qui diminue le nombre de paramètres et de calculs nécessaires dans le réseau, tout en conservant les caractéristiques importantes.\n",
    "   - **Référence**: Boureau, Y. L., Ponce, J., & LeCun, Y. (2010). A Theoretical Analysis of Feature Pooling in Visual Recognition. Proceedings of the 27th International Conference on International Conference on Machine Learning. Cette recherche explore l'impact du pooling (y compris le max pooling) sur la reconnaissance visuelle.\n",
    "\n",
    "5. **Dropout**:\n",
    "   - **Justification**: Dropout est une technique de régularisation qui aide à prévenir le surapprentissage en \"abandonnant\" aléatoirement une partie des unités neuronales pendant l'entraînement.\n",
    "   - **Référence**: Srivastava, N., Hinton, G., Krizhevsky, A., Sutskever, I., & Salakhutdinov, R. (2014). Dropout: A Simple Way to Prevent Neural Networks from Overfitting. Journal of Machine Learning Research, 15, 1929-1958. Ce papier présente Dropout et démontre son efficacité pour réduire le surapprentissage.\n",
    "\n",
    "6. **Dense + Softmax** pour la classification:\n",
    "   - **Justification**: Une couche dense est utilisée pour apprendre des combinaisons non-linéaires des caractéristiques extraites, et la fonction d'activation softmax est utilisée dans la couche de sortie pour obtenir une distribution de probabilité sur les classes.\n",
    "   - **Référence**: Goodfellow, I., Bengio, Y., Courville, A., & Bengio, Y. (2016). Deep Learning. MIT Press. Le livre offre une vue d'ensemble des réseaux de neurones, y compris l'utilisation de softmax pour la classification.\n",
    "\n",
    "7. **Adam Optimizer**:\n",
    "   - **Justification**: Adam est un optimiseur qui ajuste le taux d'apprentissage de manière adaptative pour chaque paramètre, ce qui le rend efficace pour de nombreux problèmes de deep learning. Adam fonctionne par la fonction mathématique de descente stochastique de gradients.\n",
    "   - **Référence**: Kingma, D. P., & Ba, J. (2014). Adam: A Method for Stochastic Optimization. arXiv:1412.6980. Ce papier introduit Adam et explique comment il fonctionne.\n",
    "\n",
    "8. **ImageDataGenerator pour l'augmentation de données**:\n",
    "   - **Justification**: L'augmentation de données est une technique qui crée artificiellement de nouveaux exemples d'entraînement par des transformations aléatoires des données existantes, aidant ainsi à réduire le surapprentissage.\n",
    "   - **Référence**: Shorten, C., & Khoshgoftaar, T. M. (2019). A Survey on Image Data Augmentation for Deep Learning. Journal of Big Data, 6(1), 60. Cette revue détaille différentes techniques d'augmentation de données et leur impact sur l'apprentissage profond.\n",
    "\n",
    "9. **ReduceLROnPlateau**:\n",
    "   - **Justification**: Réduire le taux d'apprentissage lorsque la métrique de performance cesse de s'améliorer peut conduire à une convergence plus fine vers le minimum de la fonction de perte.\n",
    "   - **Référence**: Bengio, Y. (2012). Practical Recommendations for Gradient-Based Training of Deep Architectures. In Neural Networks: Tricks of the Trade. Ce travail donne des recommandations sur l'ajustement du taux d'apprentissage pour améliorer l'entraînement des réseaux profonds."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
